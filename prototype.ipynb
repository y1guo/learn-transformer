{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Transformer Base Model from Attention is All You Need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "NUM_PROC = os.cpu_count()\n",
    "VOCAB_SIZE = 37000\n",
    "DATASET = \"wmt14\"\n",
    "LANG = \"de-en\"\n",
    "SOURCE_LANG = \"de\"\n",
    "TARGET_LANG = \"en\"\n",
    "MAX_SEQ_LEN = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The paper used the dataset [WMT2014](https://huggingface.co/datasets/wmt14) English-German dataset consisting of 4.5M sentence pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(DATASET, LANG) # Note: the dataset is downloaded at ~/.cache/huggingface/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 4508785 entries\n",
      "validation: 3000 entries\n",
      "test: 3003 entries\n",
      "#1\n",
      "de: Wiederaufnahme der Sitzungsperiode\n",
      "en: Resumption of the session\n",
      "#2\n",
      "de: Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.\n",
      "en: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
      "#3\n",
      "de: Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.\n",
      "en: Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\n"
     ]
    }
   ],
   "source": [
    "def probe_dataset():\n",
    "    # probe the dataset\n",
    "    for key in dataset:\n",
    "        print(f\"{key}: {len(dataset[key])} entries\")\n",
    "    # print the first 3 entries of the training set\n",
    "    for i in range(3):\n",
    "        print(f\"#{i+1}\")\n",
    "        sample = dataset[\"train\"][i]\n",
    "        for key in sample:\n",
    "            if key == \"translation\":\n",
    "                for lang in sample[key]:\n",
    "                    print(f\"{lang}: {sample[key][lang]}\")\n",
    "            else:\n",
    "                print(f\"{key}: {sample[key]}\")\n",
    "\n",
    "    \n",
    "probe_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "\n",
    "The paper used a byte-pair encoding with a shared (English + German) vocab of 37000 tokens. \n",
    "\n",
    "I want to build the tokenizer solely from this dataset. So I avoid using pre-trained tokenizer from HuggingFace.\n",
    "\n",
    "The following code follows [HuggingFace's tutorial on tokenizers](https://huggingface.co/docs/tokenizers/quicktour) .\n",
    "\n",
    "Training about 2 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "\n",
    "def batch_iterator(batch_size: int = 100):\n",
    "    for lang in [SOURCE_LANG, TARGET_LANG]:\n",
    "        for key in [\"train\", \"validation\", \"test\"]:\n",
    "            for i in range(0, len(dataset[key]), batch_size):\n",
    "                yield [item[lang] for item in dataset[key][i:i+batch_size][\"translation\"]]\n",
    "\n",
    "\n",
    "saved_tokenizer = f\"tokenizer-{DATASET}-{SOURCE_LANG}-{TARGET_LANG}.json\"\n",
    "try:\n",
    "    tokenizer = Tokenizer.from_file(saved_tokenizer)\n",
    "except:\n",
    "    tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "    trainer = BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "    tokenizer.train_from_iterator(batch_iterator(), trainer=trainer, length=sum([len(_) for _ in dataset.values()]))\n",
    "    tokenizer.save(saved_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the dataset with tokens\n",
    "\n",
    "Takes about 1 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 4508785 entries\n",
      "validation: 3000 entries\n",
      "test: 3003 entries\n",
      "#1\n",
      "de: Wiederaufnahme der Sitzungsperiode\n",
      "en: Resumption of the session\n",
      "input_ids: [28682, 3784, 27639]\n",
      "attention_mask: [1, 1, 1]\n",
      "labels: [5064, 30454, 3792, 3780, 10827]\n",
      "decoder_attention_mask: [1, 1, 1, 1, 1]\n",
      "#2\n",
      "de: Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.\n",
      "en: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
      "input_ids: [4193, 33340, 3804, 3813, 15961, 16, 3895, 5372, 18, 9212, 18543, 73, 27639, 3880, 4495, 5614, 3877, 4877, 9163, 16, 12849, 4757, 13710, 6130, 20620, 4224, 6950, 9848, 3800, 7569, 16, 4332, 3941, 10821, 8613, 7876, 18]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "labels: [45, 20701, 25857, 3780, 10827, 3792, 3780, 4081, 4507, 3863, 24032, 3811, 3772, 14753, 5372, 9079, 7696, 16, 3790, 45, 4225, 4353, 6594, 4641, 3795, 5735, 3976, 69, 9629, 4278, 4349, 3767, 3780, 5821, 3852, 3976, 15955, 69, 10613, 4981, 3939, 6653, 18]\n",
      "decoder_attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "#3\n",
      "de: Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.\n",
      "en: Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\n",
      "input_ids: [5120, 3941, 12189, 9534, 16, 3833, 3784, 3794, 26013, 3791, 6, 5660, 3765, 4779, 17, 15720, 6, 3942, 29471, 18, 7885, 4015, 5209, 11597, 4953, 4768, 10237, 3859, 29171, 26258, 9719, 18]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "labels: [9678, 16, 3786, 3976, 3977, 3966, 7771, 16, 3780, 7858, 11022, 11, 33225, 17287, 11, 12628, 3795, 6091, 4060, 16, 5149, 3780, 4524, 3767, 69, 5052, 3792, 4596, 17068, 69, 8477, 3792, 7197, 17538, 3852, 12123, 4506, 72, 4612, 4293, 18]\n",
      "decoder_attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def encode(sample):\n",
    "    encoding_src = tokenizer.encode(sample[\"translation\"][SOURCE_LANG])\n",
    "    encoding_tgt = tokenizer.encode(sample[\"translation\"][TARGET_LANG])\n",
    "    return ({\n",
    "        \"input_ids\": encoding_src.ids,\n",
    "        \"attention_mask\": encoding_src.attention_mask,\n",
    "        \"labels\": encoding_tgt.ids,\n",
    "        \"decoder_attention_mask\": encoding_tgt.attention_mask,\n",
    "    })\n",
    "\n",
    "\n",
    "for key in [\"train\", \"validation\", \"test\"]:\n",
    "    dataset[key] = dataset[key].map(encode, num_proc=NUM_PROC)\n",
    "probe_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Sequence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 6 mins\n",
    "seq_len = {\"input_ids\": [], \"labels\": []}\n",
    "for item in dataset[\"train\"]:\n",
    "    seq_len[\"input_ids\"].append(len(item[\"input_ids\"]))\n",
    "    seq_len[\"labels\"].append(len(item[\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2112% of the samples are dropped if truncated at   64 tokens\n",
      "0.1751% of the samples are dropped if truncated at  128 tokens\n",
      "0.0189% of the samples are dropped if truncated at  256 tokens\n",
      "0.0055% of the samples are dropped if truncated at  512 tokens\n",
      "0.0019% of the samples are dropped if truncated at 1024 tokens\n",
      "0.0006% of the samples are dropped if truncated at 2048 tokens\n",
      "0.0002% of the samples are dropped if truncated at 4096 tokens\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9552% of the samples are dropped if truncated at   64 tokens\n",
      "0.1661% of the samples are dropped if truncated at  128 tokens\n",
      "0.0175% of the samples are dropped if truncated at  256 tokens\n",
      "0.0055% of the samples are dropped if truncated at  512 tokens\n",
      "0.0022% of the samples are dropped if truncated at 1024 tokens\n",
      "0.0009% of the samples are dropped if truncated at 2048 tokens\n",
      "0.0005% of the samples are dropped if truncated at 4096 tokens\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "for key in seq_len:\n",
    "    seq_len[key] = np.array(seq_len[key])\n",
    "    plt.hist(seq_len[key], bins=100, log=True)\n",
    "    plt.title(key)\n",
    "    plt.show()\n",
    "    for exponent in range(6, 13):\n",
    "        truncate_len = 2 ** exponent\n",
    "        rate = np.sum(seq_len[key] > truncate_len) / len(seq_len[key])\n",
    "        print(f\"{rate * 100:<6.4f}% of the samples are dropped if truncated at {truncate_len:>4} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, during prototyping, I'll use 128 as the max sequence length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct the dataset with tokens\n",
    "\n",
    "Takes about 2 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9397f9de6d814260907f932abd8d79d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/4508785 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85f8cb682ee4e2989106b8acb982ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974e6cc96ee24d568b12a29ce7ca75dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/3003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 4508785 entries\n",
      "validation: 3000 entries\n",
      "test: 3003 entries\n",
      "#1\n",
      "input_ids: tensor([28682,  3784, 27639,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3])\n",
      "attention_mask: tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels: tensor([ 5064, 30454,  3792,  3780, 10827,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3])\n",
      "decoder_attention_mask: tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "#2\n",
      "input_ids: tensor([ 4193, 33340,  3804,  3813, 15961,    16,  3895,  5372,    18,  9212,\n",
      "        18543,    73, 27639,  3880,  4495,  5614,  3877,  4877,  9163,    16,\n",
      "        12849,  4757, 13710,  6130, 20620,  4224,  6950,  9848,  3800,  7569,\n",
      "           16,  4332,  3941, 10821,  8613,  7876,    18,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3])\n",
      "attention_mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels: tensor([   45, 20701, 25857,  3780, 10827,  3792,  3780,  4081,  4507,  3863,\n",
      "        24032,  3811,  3772, 14753,  5372,  9079,  7696,    16,  3790,    45,\n",
      "         4225,  4353,  6594,  4641,  3795,  5735,  3976,    69,  9629,  4278,\n",
      "         4349,  3767,  3780,  5821,  3852,  3976, 15955,    69, 10613,  4981,\n",
      "         3939,  6653,    18,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3])\n",
      "decoder_attention_mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "#3\n",
      "input_ids: tensor([ 5120,  3941, 12189,  9534,    16,  3833,  3784,  3794, 26013,  3791,\n",
      "            6,  5660,  3765,  4779,    17, 15720,     6,  3942, 29471,    18,\n",
      "         7885,  4015,  5209, 11597,  4953,  4768, 10237,  3859, 29171, 26258,\n",
      "         9719,    18,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3])\n",
      "attention_mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "labels: tensor([ 9678,    16,  3786,  3976,  3977,  3966,  7771,    16,  3780,  7858,\n",
      "        11022,    11, 33225, 17287,    11, 12628,  3795,  6091,  4060,    16,\n",
      "         5149,  3780,  4524,  3767,    69,  5052,  3792,  4596, 17068,    69,\n",
      "         8477,  3792,  7197, 17538,  3852, 12123,  4506,    72,  4612,  4293,\n",
      "           18,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3])\n",
      "decoder_attention_mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "tokenizer.enable_padding(pad_id=tokenizer.token_to_id(\"[PAD]\"), pad_token=\"[PAD]\", length=MAX_SEQ_LEN)\n",
    "tokenizer.enable_truncation(max_length=MAX_SEQ_LEN)\n",
    "for key in [\"train\", \"validation\", \"test\"]:\n",
    "    dataset[key] = dataset[key].map(encode, num_proc=NUM_PROC)\n",
    "probe_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "dataloader = {}\n",
    "for key in [\"train\", \"validation\", \"test\"]:\n",
    "    dataset[key].set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\", \"decoder_attention_mask\"])\n",
    "    dataloader[key] = torch.utils.data.DataLoader(dataset[key], batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   13,  4939,  3953,  ...,     3,     3,     3],\n",
      "        [ 4153, 15997, 19867,  ...,     3,     3,     3],\n",
      "        [18912,  3941,  3956,  ...,     3,     3,     3],\n",
      "        ...,\n",
      "        [31704,  5308,  3784,  ...,     3,     3,     3],\n",
      "        [ 4290,  9949,  3771,  ...,     3,     3,     3],\n",
      "        [ 4835,  3784, 16312,  ...,     3,     3,     3]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[   13,  5910,  4368,  ...,     3,     3,     3],\n",
      "        [   37,  4278, 30199,  ...,     3,     3,     3],\n",
      "        [ 4935,  4017,  4086,  ...,     3,     3,     3],\n",
      "        ...,\n",
      "        [ 4805,  5638,  3976,  ...,     3,     3,     3],\n",
      "        [ 3775,  3780,  4872,  ...,     3,     3,     3],\n",
      "        [ 6043, 16312,  3822,  ...,     3,     3,     3]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader[\"train\"]:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model: int = 512, nhead: int = 8, num_encoder_layers: int = 6, num_decoder_layers: int = 6,\n",
    "                 dim_feedforward: int = 2048, dropout: int = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        self.num_decoder_layers = num_decoder_layers\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "        self.dropout = dropout\n",
    "\n",
    "# allow adding new methods to a class\n",
    "def add_method(cls):\n",
    "    def decorator(func):\n",
    "        setattr(cls, func.__name__, func)\n",
    "        return func\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Layer\n",
    "\n",
    "The same layer (weights) is used for both the input and output embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(Transformer)\n",
    "def embedding(self, x: torch.Tensor):\n",
    "    if not hasattr(self, \"_embedding\"):\n",
    "        self._embedding = nn.Embedding(tokenizer.get_vocab_size(), self.d_model)\n",
    "    return self._embedding(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(Transformer)\n",
    "def pos_encoding(self, x: torch.Tensor):\n",
    "    if not hasattr(self, \"_pos_encoding\"):\n",
    "        pos = torch.arange(0, x.shape[1], dtype=torch.float32).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38076211 0.46243897 0.82224138 0.27802744 0.68888738]\n",
      "[0.38076211 0.46243897 0.82224138 0.27802744 0.68888738]\n"
     ]
    }
   ],
   "source": [
    "@add_method(Transformer)\n",
    "def forward(self, x: torch.Tensor):\n",
    "    # x: (batch_size, seq_len)\n",
    "    x = self.embedding(x) * torch.sqrt(self.d_model) + self.positional_encoding(x)\n",
    "    # x: (batch_size, seq_len, d_model)\n",
    "    return x\n",
    "\n",
    "\n",
    "model = Transformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
