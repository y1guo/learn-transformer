{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Transformer Base Model from Attention is All You Need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  32\n",
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import os, torch, gc\n",
    "\n",
    "\n",
    "NUM_PROC = os.cpu_count()\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "VOCAB_SIZE = 37000\n",
    "DATASET = \"wmt14\"\n",
    "LANG = \"de-en\"\n",
    "SOURCE_LANG = \"de\"\n",
    "TARGET_LANG = \"en\"\n",
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_PERCENTAGE = 1\n",
    "\n",
    "\n",
    "print(\"Number of processors: \", NUM_PROC)\n",
    "print(\"Device: \", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The paper used the dataset [WMT2014](https://huggingface.co/datasets/wmt14) English-German dataset consisting of 4.5M sentence pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, disable_caching\n",
    "\n",
    "\n",
    "disable_caching() # avoid disk explosion\n",
    "# Note: the dataset is downloaded at ~/.cache/huggingface/datasets\n",
    "dataset = {\n",
    "    \"train\": load_dataset(DATASET, LANG, split=f\"train[:{TRAIN_PERCENTAGE}%]\"),\n",
    "    \"validation\": load_dataset(DATASET, LANG, split=\"validation\"),\n",
    "    \"test\": load_dataset(DATASET, LANG, split=\"test\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 45088 entries\n",
      "validation: 3000 entries\n",
      "test: 3003 entries\n",
      "#1\n",
      "de: Wiederaufnahme der Sitzungsperiode\n",
      "en: Resumption of the session\n",
      "#2\n",
      "de: Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.\n",
      "en: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
      "#3\n",
      "de: Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.\n",
      "en: Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\n"
     ]
    }
   ],
   "source": [
    "def probe_dataset():\n",
    "    # probe the dataset\n",
    "    for key in dataset:\n",
    "        print(f\"{key}: {len(dataset[key])} entries\")\n",
    "    # print the first 3 entries of the training set\n",
    "    for i in range(3):\n",
    "        print(f\"#{i+1}\")\n",
    "        sample = dataset[\"train\"][i]\n",
    "        for key in sample:\n",
    "            if key == \"translation\":\n",
    "                for lang in sample[key]:\n",
    "                    print(f\"{lang}: {sample[key][lang]}\")\n",
    "            else:\n",
    "                print(f\"{key}: {sample[key]}\")\n",
    "\n",
    "    \n",
    "probe_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "\n",
    "The paper used a byte-pair encoding with a shared (English + German) vocab of 37000 tokens. \n",
    "\n",
    "I want to build the tokenizer solely from this dataset. So I avoid using pre-trained tokenizer from HuggingFace.\n",
    "\n",
    "The following code follows [HuggingFace's tutorial on tokenizers](https://huggingface.co/docs/tokenizers/quicktour) .\n",
    "\n",
    "Training about 2 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "\n",
    "def batch_iterator(batch_size: int = 100):\n",
    "    for lang in [SOURCE_LANG, TARGET_LANG]:\n",
    "        for key in [\"train\", \"validation\", \"test\"]:\n",
    "            for i in range(0, len(dataset[key]), batch_size):\n",
    "                yield [item[lang] for item in dataset[key][i:i+batch_size][\"translation\"]]\n",
    "\n",
    "\n",
    "saved_tokenizer = f\"tokenizer-{DATASET}-{SOURCE_LANG}-{TARGET_LANG}.json\"\n",
    "try:\n",
    "    tokenizer = Tokenizer.from_file(saved_tokenizer)\n",
    "except:\n",
    "    tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "    trainer = BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "    tokenizer.train_from_iterator(batch_iterator(), trainer=trainer, length=sum([len(_) for _ in dataset.values()]))\n",
    "    tokenizer.save(saved_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the dataset with tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sample):\n",
    "    encoding_src = tokenizer.encode(\"[CLS]\", sample[\"translation\"][SOURCE_LANG])\n",
    "    encoding_tgt = tokenizer.encode(\"[CLS]\", sample[\"translation\"][TARGET_LANG])\n",
    "    return ({\n",
    "        \"input_ids\": encoding_src.ids,\n",
    "        \"attention_mask\": torch.tensor(encoding_src.attention_mask) == 0,\n",
    "        \"labels\": encoding_tgt.ids,\n",
    "        \"decoder_attention_mask\": torch.tensor(encoding_tgt.attention_mask) == 0,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5fb39380be4e2b9f64d4df513678f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/45088 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dc6494100f4987aec596e54e7fdf75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712d7a0aead6459b8341521a7b6e2c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/3003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 45088 entries\n",
      "validation: 3000 entries\n",
      "test: 3003 entries\n",
      "#1\n",
      "de: Wiederaufnahme der Sitzungsperiode\n",
      "en: Resumption of the session\n",
      "input_ids: [1, 28682, 3784, 27639]\n",
      "attention_mask: [False, False, False, False]\n",
      "labels: [1, 5064, 30454, 3792, 3780, 10827]\n",
      "decoder_attention_mask: [False, False, False, False, False, False]\n",
      "#2\n",
      "de: Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.\n",
      "en: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
      "input_ids: [1, 4193, 33340, 3804, 3813, 15961, 16, 3895, 5372, 18, 9212, 18543, 73, 27639, 3880, 4495, 5614, 3877, 4877, 9163, 16, 12849, 4757, 13710, 6130, 20620, 4224, 6950, 9848, 3800, 7569, 16, 4332, 3941, 10821, 8613, 7876, 18]\n",
      "attention_mask: [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "labels: [1, 45, 20701, 25857, 3780, 10827, 3792, 3780, 4081, 4507, 3863, 24032, 3811, 3772, 14753, 5372, 9079, 7696, 16, 3790, 45, 4225, 4353, 6594, 4641, 3795, 5735, 3976, 69, 9629, 4278, 4349, 3767, 3780, 5821, 3852, 3976, 15955, 69, 10613, 4981, 3939, 6653, 18]\n",
      "decoder_attention_mask: [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "#3\n",
      "de: Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.\n",
      "en: Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\n",
      "input_ids: [1, 5120, 3941, 12189, 9534, 16, 3833, 3784, 3794, 26013, 3791, 6, 5660, 3765, 4779, 17, 15720, 6, 3942, 29471, 18, 7885, 4015, 5209, 11597, 4953, 4768, 10237, 3859, 29171, 26258, 9719, 18]\n",
      "attention_mask: [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "labels: [1, 9678, 16, 3786, 3976, 3977, 3966, 7771, 16, 3780, 7858, 11022, 11, 33225, 17287, 11, 12628, 3795, 6091, 4060, 16, 5149, 3780, 4524, 3767, 69, 5052, 3792, 4596, 17068, 69, 8477, 3792, 7197, 17538, 3852, 12123, 4506, 72, 4612, 4293, 18]\n",
      "decoder_attention_mask: [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "# Takes 1 min\n",
    "for key in [\"train\", \"validation\", \"test\"]:\n",
    "    dataset[key] = dataset[key].map(encode, num_proc=NUM_PROC)\n",
    "probe_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Sequence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 6 mins\n",
    "seq_len = {\"input_ids\": [], \"labels\": []}\n",
    "for item in dataset[\"train\"]:\n",
    "    seq_len[\"input_ids\"].append(len(item[\"input_ids\"]))\n",
    "    seq_len[\"labels\"].append(len(item[\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2112% of the samples are dropped if truncated at   64 tokens\n",
      "0.1751% of the samples are dropped if truncated at  128 tokens\n",
      "0.0189% of the samples are dropped if truncated at  256 tokens\n",
      "0.0055% of the samples are dropped if truncated at  512 tokens\n",
      "0.0019% of the samples are dropped if truncated at 1024 tokens\n",
      "0.0006% of the samples are dropped if truncated at 2048 tokens\n",
      "0.0002% of the samples are dropped if truncated at 4096 tokens\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9552% of the samples are dropped if truncated at   64 tokens\n",
      "0.1661% of the samples are dropped if truncated at  128 tokens\n",
      "0.0175% of the samples are dropped if truncated at  256 tokens\n",
      "0.0055% of the samples are dropped if truncated at  512 tokens\n",
      "0.0022% of the samples are dropped if truncated at 1024 tokens\n",
      "0.0009% of the samples are dropped if truncated at 2048 tokens\n",
      "0.0005% of the samples are dropped if truncated at 4096 tokens\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "for key in seq_len:\n",
    "    seq_len[key] = np.array(seq_len[key])\n",
    "    plt.hist(seq_len[key], bins=100, log=True)\n",
    "    plt.title(key)\n",
    "    plt.show()\n",
    "    for exponent in range(6, 13):\n",
    "        truncate_len = 2 ** exponent\n",
    "        rate = np.sum(seq_len[key] > truncate_len) / len(seq_len[key])\n",
    "        print(f\"{rate * 100:<6.4f}% of the samples are dropped if truncated at {truncate_len:>4} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, during prototyping, I'll use 128 as the max sequence length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct the dataset with tokens\n",
    "\n",
    "Takes about 2 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7688aeb22042da8a7941962944051c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/45088 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ed0dd8a84543f9bef8de5fdc87fd6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cae83a008304750a49bdb77204864f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/3003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 45088 entries\n",
      "validation: 3000 entries\n",
      "test: 3003 entries\n",
      "#1\n",
      "de: Wiederaufnahme der Sitzungsperiode\n",
      "en: Resumption of the session\n",
      "input_ids: [1, 28682, 3784, 27639, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "attention_mask: [False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "labels: [1, 5064, 30454, 3792, 3780, 10827, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "decoder_attention_mask: [False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "#2\n",
      "de: Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.\n",
      "en: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
      "input_ids: [1, 4193, 33340, 3804, 3813, 15961, 16, 3895, 5372, 18, 9212, 18543, 73, 27639, 3880, 4495, 5614, 3877, 4877, 9163, 16, 12849, 4757, 13710, 6130, 20620, 4224, 6950, 9848, 3800, 7569, 16, 4332, 3941, 10821, 8613, 7876, 18, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "attention_mask: [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "labels: [1, 45, 20701, 25857, 3780, 10827, 3792, 3780, 4081, 4507, 3863, 24032, 3811, 3772, 14753, 5372, 9079, 7696, 16, 3790, 45, 4225, 4353, 6594, 4641, 3795, 5735, 3976, 69, 9629, 4278, 4349, 3767, 3780, 5821, 3852, 3976, 15955, 69, 10613, 4981, 3939, 6653, 18, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "decoder_attention_mask: [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "#3\n",
      "de: Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.\n",
      "en: Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\n",
      "input_ids: [1, 5120, 3941, 12189, 9534, 16, 3833, 3784, 3794, 26013, 3791, 6, 5660, 3765, 4779, 17, 15720, 6, 3942, 29471, 18, 7885, 4015, 5209, 11597, 4953, 4768, 10237, 3859, 29171, 26258, 9719, 18, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "attention_mask: [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "labels: [1, 9678, 16, 3786, 3976, 3977, 3966, 7771, 16, 3780, 7858, 11022, 11, 33225, 17287, 11, 12628, 3795, 6091, 4060, 16, 5149, 3780, 4524, 3767, 69, 5052, 3792, 4596, 17068, 69, 8477, 3792, 7197, 17538, 3852, 12123, 4506, 72, 4612, 4293, 18, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "decoder_attention_mask: [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "tokenizer.enable_padding(pad_id=tokenizer.token_to_id(\"[PAD]\"), pad_token=\"[PAD]\", length=MAX_SEQ_LEN)\n",
    "tokenizer.enable_truncation(max_length=MAX_SEQ_LEN)\n",
    "for key in [\"train\", \"validation\", \"test\"]:\n",
    "    dataset[key] = dataset[key].map(encode, num_proc=NUM_PROC)\n",
    "probe_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = {}\n",
    "for key in [\"train\", \"validation\", \"test\"]:\n",
    "    dataset[key].set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\", \"decoder_attention_mask\"])\n",
    "    dataloader[key] = torch.utils.data.DataLoader(dataset[key], batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    1, 29297,   185,  ...,     3,     3,     3],\n",
      "        [    1,  4317,  6747,  ...,     3,     3,     3],\n",
      "        [    1,     6,  3974,  ...,     3,     3,     3],\n",
      "        ...,\n",
      "        [    1,  3974, 26838,  ...,     3,     3,     3],\n",
      "        [    1,  7881,  3818,  ...,     3,     3,     3],\n",
      "        [    1,  7134,  4307,  ...,     3,     3,     3]]), 'attention_mask': tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]]), 'labels': tensor([[    1,    57,  3782,  ...,     3,     3,     3],\n",
      "        [    1,  4181,  3774,  ...,     3,     3,     3],\n",
      "        [    1,     6, 11178,  ...,     3,     3,     3],\n",
      "        ...,\n",
      "        [    1,  3887,  7142,  ...,     3,     3,     3],\n",
      "        [    1,  4553,  6854,  ...,     3,     3,     3],\n",
      "        [    1,  3871,  7134,  ...,     3,     3,     3]]), 'decoder_attention_mask': tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]])}\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader[\"validation\"]:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "def pos_encoding(seq_len: int, d_model: int):\n",
    "    pos = torch.arange(0, seq_len)[None, :, None]\n",
    "    idx = torch.arange(0, d_model)[None, None, :]\n",
    "    wavlen = 10000 ** (idx / d_model)\n",
    "    return torch.sin(pos / wavlen) * (1 - idx % 2) + torch.cos(pos / wavlen) * (idx % 2)\n",
    "\n",
    "\n",
    "class InverseEmbedding(nn.Module):\n",
    "    def __init__(self, embedding: nn.Embedding):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: (batch_size, seq_len, d_model)\n",
    "        return x @ self.embedding.weight.data.T\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model: int = 512, nhead: int = 8, num_encoder_layers: int = 6, num_decoder_layers: int = 6,\n",
    "                 dim_feedforward: int = 2048, dropout: int = 0.1):\n",
    "        super().__init__()\n",
    "        # hyperparameters\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.num_encoder_layers = num_encoder_layers\n",
    "        self.num_decoder_layers = num_decoder_layers\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "        self.dropout = dropout\n",
    "        # embedding layer\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, d_model)\n",
    "        self.inverse_embedding = InverseEmbedding(self.embedding)\n",
    "        # positional encoding\n",
    "        self.pos_encoding = pos_encoding(MAX_SEQ_LEN, d_model).to(DEVICE)\n",
    "        # transformer layers\n",
    "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers, \n",
    "                                          num_decoder_layers=num_decoder_layers, dim_feedforward=dim_feedforward, \n",
    "                                          dropout=dropout, batch_first=True)\n",
    "        self.tgt_mask = torch.triu(torch.full((MAX_SEQ_LEN, MAX_SEQ_LEN), True), diagonal=1).to(DEVICE)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, x_mask: torch.Tensor, y: torch.Tensor, y_mask: torch.Tensor):\n",
    "        # x, y: (batch_size, seq_len)\n",
    "        x = self.embedding(x) * torch.tensor(self.d_model).to(DEVICE)**0.5 + self.pos_encoding\n",
    "        y = self.embedding(y) * torch.tensor(self.d_model).to(DEVICE)**0.5 + self.pos_encoding\n",
    "        # x, y: (batch_size, seq_len, d_model), x_mask, y_mask: (batch_size, seq_len)\n",
    "        output = self.transformer(x, y, src_key_padding_mask=x_mask, tgt_key_padding_mask=y_mask, \n",
    "                                  memory_key_padding_mask=x_mask, tgt_mask=self.tgt_mask)\n",
    "        # output: (batch_size, seq_len, d_model)\n",
    "        output = self.inverse_embedding(output)\n",
    "        # output: (batch_size, seq_len, vocab_size)\n",
    "        return output\n",
    "\n",
    "\n",
    "model = Transformer().to(DEVICE)\n",
    "# for batch in dataloader[\"train\"]:\n",
    "#     x, x_mask, y, y_mask = batch.values()\n",
    "#     x, x_mask, y, y_mask = x.to(DEVICE), x_mask.to(DEVICE), y.to(DEVICE), y_mask.to(DEVICE)\n",
    "#     print(\"x, x_match, y, y_match =\", x.shape, x_mask.shape, y.shape, y_mask.shape)\n",
    "#     pred = model(x, x_mask, y, y_mask)\n",
    "#     print(\"pred =\", pred.shape)\n",
    "#     print(pred)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test\n",
    "\n",
    "The training and testing code follows the template from [PyTorch Tutorial](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, scheduler):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for i_batch, batch in enumerate(dataloader):\n",
    "        x, x_mask, y, y_mask = batch.values()\n",
    "        x, x_mask, y, y_mask = x.to(DEVICE), x_mask.to(DEVICE), y.to(DEVICE), y_mask.to(DEVICE)\n",
    "\n",
    "        # Compute prediction error\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x, x_mask, y, y_mask)[:, :-1, :]\n",
    "        label = y[:, 1:]\n",
    "        # pred: (batch_size, seq_len, vocab_size), y: (batch_size, seq_len)\n",
    "        loss = loss_fn(pred.transpose(-1, -2), label)\n",
    "\n",
    "        # Optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if i_batch % 100 == 0:\n",
    "            loss, current = loss.item(), (i_batch + 1) * BATCH_SIZE\n",
    "            correct = (pred.argmax(-1) == label).type(torch.float).sum().item() / label.numel()\n",
    "            print(f\"Accuracy: {100*correct:>0.1f}%, Avg loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def validate(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    # model.eval() # Note: this triggers some optimized behavior which causes trouble with our setup\n",
    "    model.train()\n",
    "    validation_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x, x_mask, y, y_mask = batch.values()\n",
    "            x, x_mask, y, y_mask = x.to(DEVICE), x_mask.to(DEVICE), y.to(DEVICE), y_mask.to(DEVICE)\n",
    "            pred = model(x, x_mask, y, y_mask)[:, :-1, :]\n",
    "            label = y[:, 1:]\n",
    "            validation_loss += loss_fn(pred.transpose(-1, -2), label).item()\n",
    "            correct += (pred.argmax(-1) == label).type(torch.float).sum().item()\n",
    "            total += label.numel()\n",
    "    validation_loss /= num_batches\n",
    "    correct /= total\n",
    "    print(f\"Validation Error: \\n Accuracy: {100*correct:>0.1f}%, Avg loss: {validation_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "def run(dataloader, model, loss_fn, optimizer, scheduler, epochs=5):\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(dataloader[\"train\"], model, loss_fn, optimizer, scheduler)\n",
    "        validate(dataloader[\"validation\"], model, loss_fn)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The learning rate schedule used in the paper\n",
    "\n",
    "$$lr = d_{\\rm model}^{-0.5}\\cdot \\min(step\\_num^{-0.5}, step\\_num\\cdot warmup\\_steps^{-1.5})$$\n",
    "\n",
    "where $warmup\\_steps = 4000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epoch = np.linspace(1, 20000, 200)\n",
    "x = n_epoch[n_epoch <= 4000]\n",
    "plt.plot(x, 512**-0.5 * x * 4000**-1.5, label=\"warmup\")\n",
    "x = n_epoch[n_epoch > 4000]\n",
    "plt.plot(x, 512**-0.5 * x**-0.5, label=\"decay\")\n",
    "plt.xlabel(\"num steps\")\n",
    "plt.ylabel(\"learning rate\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Accuracy: 75.6%, Avg loss: 7.648376  [   64/45088]\n",
      "Accuracy: 76.0%, Avg loss: 7.544426  [ 6464/45088]\n",
      "Accuracy: 75.1%, Avg loss: 7.600710  [12864/45088]\n",
      "Accuracy: 79.3%, Avg loss: 6.293508  [19264/45088]\n",
      "Accuracy: 82.0%, Avg loss: 5.373775  [25664/45088]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mLambdaLR(optimizer, \u001b[39mlambda\u001b[39;00m nstep: \u001b[39mmin\u001b[39m((nstep \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m, (nstep \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m4000\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1.5\u001b[39m))\n\u001b[1;32m      3\u001b[0m loss_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss() \u001b[39m# could add label smoothing\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m run(dataloader, model, loss_fn, optimizer, scheduler)\n",
      "Cell \u001b[0;32mIn[30], line 48\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(dataloader, model, loss_fn, optimizer, scheduler, epochs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     47\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m     train(dataloader[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m], model, loss_fn, optimizer, scheduler)\n\u001b[1;32m     49\u001b[0m     validate(dataloader[\u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m], model, loss_fn)\n\u001b[1;32m     50\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[30], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer, scheduler)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39m# Compute prediction error\u001b[39;00m\n\u001b[1;32m      9\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m pred \u001b[39m=\u001b[39m model(x, x_mask, y, y_mask)[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[1;32m     11\u001b[0m label \u001b[39m=\u001b[39m y[:, \u001b[39m1\u001b[39m:]\n\u001b[1;32m     12\u001b[0m \u001b[39m# pred: (batch_size, seq_len, vocab_size), y: (batch_size, seq_len)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-transformer/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[14], line 50\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, x_mask, y, y_mask)\u001b[0m\n\u001b[1;32m     48\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(y) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model)\u001b[39m.\u001b[39mto(DEVICE)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m0.5\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_encoding\n\u001b[1;32m     49\u001b[0m \u001b[39m# x, y: (batch_size, seq_len, d_model), x_mask, y_mask: (batch_size, seq_len)\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(x, y, src_key_padding_mask\u001b[39m=\u001b[39;49mx_mask, tgt_key_padding_mask\u001b[39m=\u001b[39;49my_mask, \n\u001b[1;32m     51\u001b[0m                           memory_key_padding_mask\u001b[39m=\u001b[39;49mx_mask, tgt_mask\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtgt_mask)\n\u001b[1;32m     52\u001b[0m \u001b[39m# output: (batch_size, seq_len, d_model)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minverse_embedding(output)\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-transformer/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-transformer/lib/python3.10/site-packages/torch/nn/modules/transformer.py:145\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m src\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model \u001b[39mor\u001b[39;00m tgt\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model:\n\u001b[1;32m    143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m memory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(src, mask\u001b[39m=\u001b[39;49msrc_mask, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask)\n\u001b[1;32m    146\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(tgt, memory, tgt_mask\u001b[39m=\u001b[39mtgt_mask, memory_mask\u001b[39m=\u001b[39mmemory_mask,\n\u001b[1;32m    147\u001b[0m                       tgt_key_padding_mask\u001b[39m=\u001b[39mtgt_key_padding_mask,\n\u001b[1;32m    148\u001b[0m                       memory_key_padding_mask\u001b[39m=\u001b[39mmemory_key_padding_mask)\n\u001b[1;32m    149\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-transformer/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-transformer/lib/python3.10/site-packages/torch/nn/modules/transformer.py:315\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_causal \u001b[39m=\u001b[39m make_causal\n\u001b[1;32m    314\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 315\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, is_causal\u001b[39m=\u001b[39;49mis_causal, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask_for_layers)\n\u001b[1;32m    317\u001b[0m \u001b[39mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    318\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto_padded_tensor(\u001b[39m0.\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-transformer/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/learn-transformer/lib/python3.10/site-packages/torch/nn/modules/transformer.py:591\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    589\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x))\n\u001b[1;32m    590\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm1(x \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[39m=\u001b[39;49mis_causal))\n\u001b[1;32m    592\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[1;32m    594\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=512**-0.5, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda nstep: min((nstep + 1) ** -0.5, (nstep + 1) * 4000 ** -1.5))\n",
    "loss_fn = nn.CrossEntropyLoss() # could add label smoothing\n",
    "run(dataloader, model, loss_fn, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free Up Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   1656 MiB |  12872 MiB |  45943 GiB |  45941 GiB |\n",
      "|       from large pool |   1619 MiB |  12777 MiB |  45789 GiB |  45787 GiB |\n",
      "|       from small pool |     37 MiB |    147 MiB |    154 GiB |    154 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   1656 MiB |  12872 MiB |  45943 GiB |  45941 GiB |\n",
      "|       from large pool |   1619 MiB |  12777 MiB |  45789 GiB |  45787 GiB |\n",
      "|       from small pool |     37 MiB |    147 MiB |    154 GiB |    154 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |   1654 MiB |  12867 MiB |  45917 GiB |  45915 GiB |\n",
      "|       from large pool |   1617 MiB |  12772 MiB |  45763 GiB |  45761 GiB |\n",
      "|       from small pool |     37 MiB |    147 MiB |    154 GiB |    154 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   2730 MiB |  13756 MiB |  23104 MiB |  20374 MiB |\n",
      "|       from large pool |   2688 MiB |  13606 MiB |  22886 MiB |  20198 MiB |\n",
      "|       from small pool |     42 MiB |    150 MiB |    218 MiB |    176 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   1073 MiB |   2252 MiB |  17359 GiB |  17358 GiB |\n",
      "|       from large pool |   1068 MiB |   2245 MiB |  17205 GiB |  17203 GiB |\n",
      "|       from small pool |      4 MiB |      8 MiB |    154 GiB |    154 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     381    |    1499    |    2489 K  |    2489 K  |\n",
      "|       from large pool |      89    |     483    |    1512 K  |    1512 K  |\n",
      "|       from small pool |     292    |    1151    |     977 K  |     977 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     381    |    1499    |    2489 K  |    2489 K  |\n",
      "|       from large pool |      89    |     483    |    1512 K  |    1512 K  |\n",
      "|       from small pool |     292    |    1151    |     977 K  |     977 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      46    |     262    |     463    |     417    |\n",
      "|       from large pool |      25    |     192    |     354    |     329    |\n",
      "|       from small pool |      21    |      75    |     109    |      88    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      29    |      75    |     959 K  |     959 K  |\n",
      "|       from large pool |      19    |      65    |     591 K  |     591 K  |\n",
      "|       from small pool |      10    |      22    |     367 K  |     367 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def free_memory(*args):\n",
    "    for name in args:\n",
    "        try:\n",
    "            arg = globals()[name]\n",
    "            arg.to(\"cpu\")\n",
    "            del arg\n",
    "        except KeyError:\n",
    "            pass\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(torch.cuda.memory_summary())\n",
    "\n",
    "\n",
    "free_memory(\"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
