{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Transformer from Attention is All You Need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  32\n",
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from dataset import Dataset\n",
    "from tokenizer import get_tokenizer\n",
    "from utils import NUM_PROC, DEVICE, free_memory\n",
    "from model import TransformerModel\n",
    "from transformer import Transformer\n",
    "\n",
    "\n",
    "print(\"Number of processors: \", NUM_PROC)\n",
    "print(\"Device: \", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Lite from Scratch\n",
    "\n",
    "Using half the dimension as the base model: $d_{\\rm model} = 256$, $d_{\\rm ff} = 1024$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "\n",
    "Byte-Pair Encoding with shared (English + German) vocabulary of 37000 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer from ../tokenizer-wmt14-de-en.json\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer(name=\"wmt14\", language=\"de-en\", vocab_size=37000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset is downloaded at ~/.cache/huggingface/datasets/. I've turned off dataset caching to avoid disk explosion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(name=\"wmt14\", language=\"de-en\", percentage=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e88c186e37d4db5879136b67b412f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/45088 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86eafef347404f49b3dfb74c5023a15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0b61cde73b4493976ab4cf4876d9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/3003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.tokenize(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da6ab7630c24bc49374e3b13bae90d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/45088 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e468b0f426bb4bbd94b97e30d3411689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/45025 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70d4da04e0d480783f3a52bb5ba44f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b96228aa814280905977d6dbfee555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/2999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c46f512bf34f63b80c8d0155ac7816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849cccfda37f4a46b51bec339ce130ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/3003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataloader = {}\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    dataloader[split] = dataset.get_dataloader(split=split, batch_size=64, shuffle=True, min_len=1, max_len=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the transformer model\n",
    "model = TransformerModel(vocab_size=tokenizer.get_vocab_size(), d_model=256, dim_feedforward=1024).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=512**-0.5, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda nstep: min((nstep + 1) ** -0.5, (nstep + 1) * 4000 ** -1.5))\n",
    "loss_fn = nn.CrossEntropyLoss() # could add label smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# model.load_state_dict(torch.load(\"model_1.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  80348 KiB |  80348 KiB |  80348 KiB |      0 B   |\n",
      "|       from large pool |  37000 KiB |  37000 KiB |  37000 KiB |      0 B   |\n",
      "|       from small pool |  43348 KiB |  43348 KiB |  43348 KiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  80348 KiB |  80348 KiB |  80348 KiB |      0 B   |\n",
      "|       from large pool |  37000 KiB |  37000 KiB |  37000 KiB |      0 B   |\n",
      "|       from small pool |  43348 KiB |  43348 KiB |  43348 KiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  80348 KiB |  80348 KiB |  80348 KiB |      0 B   |\n",
      "|       from large pool |  37000 KiB |  37000 KiB |  37000 KiB |      0 B   |\n",
      "|       from small pool |  43348 KiB |  43348 KiB |  43348 KiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  83968 KiB |  83968 KiB |  83968 KiB |      0 B   |\n",
      "|       from large pool |  38912 KiB |  38912 KiB |  38912 KiB |      0 B   |\n",
      "|       from small pool |  45056 KiB |  45056 KiB |  45056 KiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   3620 KiB |   3816 KiB |  27640 KiB |  24020 KiB |\n",
      "|       from large pool |   1912 KiB |   1912 KiB |   1912 KiB |      0 KiB |\n",
      "|       from small pool |   1708 KiB |   1920 KiB |  25728 KiB |  24020 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     187    |     187    |     187    |       0    |\n",
      "|       from large pool |       1    |       1    |       1    |       0    |\n",
      "|       from small pool |     186    |     186    |     186    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     187    |     187    |     187    |       0    |\n",
      "|       from large pool |       1    |       1    |       1    |       0    |\n",
      "|       from small pool |     186    |     186    |     186    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      23    |      23    |      23    |       0    |\n",
      "|       from large pool |       1    |       1    |       1    |       0    |\n",
      "|       from small pool |      22    |      22    |      22    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       5    |       5    |      23    |      18    |\n",
      "|       from large pool |       1    |       1    |       1    |       0    |\n",
      "|       from small pool |       4    |       4    |      22    |      18    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# free_memory(\"model\")\n",
    "free_memory()\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the transformer wrapper\n",
    "transformer = Transformer(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Epoch 1/1\n",
      "Accuracy: 0.0%, Avg loss: 67.911957  [   64/45025]  [0:00:01 < 0:14:59]\n",
      "Accuracy: 0.8%, Avg loss: 38.382389  [ 6464/45025]  [0:00:11 < 0:01:08]\n",
      "Accuracy: 1.0%, Avg loss: 32.601387  [12864/45025]  [0:00:20 < 0:00:51]\n",
      "Accuracy: 3.0%, Avg loss: 29.933926  [19264/45025]  [0:00:30 < 0:00:40]\n",
      "Accuracy: 4.7%, Avg loss: 27.682467  [25664/45025]  [0:00:40 < 0:00:30]\n",
      "Accuracy: 5.1%, Avg loss: 27.091312  [32064/45025]  [0:00:51 < 0:00:20]\n",
      "Accuracy: 9.1%, Avg loss: 26.094402  [38464/45025]  [0:01:01 < 0:00:10]\n",
      "Accuracy: 8.0%, Avg loss: 25.695353  [44864/45025]  [0:01:10 < 0:00:00]\n",
      "Validation Error: \n",
      " Accuracy: 7.4%, Avg loss: 27.908228 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "transformer.train(dataloader, model, loss_fn, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 20.5%\n",
      "\u001b[31mIn\u001b[39m\n",
      "\" \u001b[31mIn\u001b[39m\n",
      "\" According \u001b[32mto\u001b[39m\n",
      "\" According to \u001b[31mthe\u001b[39m\n",
      "\" According to current \u001b[31msituation\u001b[39m\n",
      "\" According to current measurements \u001b[32m,\u001b[39m\n",
      "\" According to current measurements , \u001b[31mthe\u001b[39m\n",
      "\" According to current measurements , around \u001b[31mthe\u001b[39m\n",
      "\" According to current measurements , around 12 \u001b[31m%\u001b[39m\n",
      "\" According to current measurements , around 12 , \u001b[31mthe\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 \u001b[31mpeople\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles \u001b[31mare\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel \u001b[31mare\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through \u001b[32mthe\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the \u001b[31mHervor\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town \u001b[32mof\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of \u001b[31mthe\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut \u001b[31m-\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach \u001b[31m,\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on \u001b[32mthe\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the \u001b[31mbasis\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B \u001b[31m,\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 \u001b[31m,\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on \u001b[31mthe\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a \u001b[31mnumber\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily \u001b[32mbasis\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis \u001b[32m,\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis , \u001b[31mthe\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis , of \u001b[31mthe\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis , of which \u001b[31mare\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis , of which heavy \u001b[31mw\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis , of which heavy goods \u001b[31mare\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis , of which heavy goods traffic \u001b[31mare\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis , of which heavy goods traffic accounts \u001b[31mare\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis , of which heavy goods traffic accounts for \u001b[31mthe\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis , of which heavy goods traffic accounts for around \u001b[31mthe\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis , of which heavy goods traffic accounts for around ten \u001b[31myears\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis , of which heavy goods traffic accounts for around ten per \u001b[31myear\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis , of which heavy goods traffic accounts for around ten per cent \u001b[31mof\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis , of which heavy goods traffic accounts for around ten per cent ,\" \u001b[31m.\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis , of which heavy goods traffic accounts for around ten per cent ,\" emphasised \u001b[31m.\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis , of which heavy goods traffic accounts for around ten per cent ,\" emphasised Arn \u001b[31m.\u001b[39m\n",
      "\" According to current measurements , around 12 , 000 vehicles travel through the town of Gut ach on the B 33 on a daily basis , of which heavy goods traffic accounts for around ten per cent ,\" emphasised Arn old \u001b[32m.\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "sample = dataset.dataset[\"test\"][\"translation\"][10]\n",
    "transformer.predict(sample[\"de\"], sample[\"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a good thing .\n"
     ]
    }
   ],
   "source": [
    "print(transformer.translate(\"Ich bin ein Berliner.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1\n",
      "Source: Gutach: Noch mehr Sicherheit für Fußgänger\n",
      "Target: Gutach: Increased safety for pedestrians\n",
      "Prediction: I have been able to make a great deal of work for the situation .\n",
      "\n",
      "#2\n",
      "Source: Sie stehen keine 100 Meter voneinander entfernt: Am Dienstag ist in Gutach die neue B 33-Fußgängerampel am Dorfparkplatz in Betrieb genommen worden - in Sichtweite der älteren Rathausampel.\n",
      "Target: They are not even 100 metres apart: On Tuesday, the new B 33 pedestrian lights in Dorfparkplatz in Gutach became operational - within view of the existing Town Hall traffic lights.\n",
      "Prediction: It is not a great deal of the new new groups in the new procedure , which is not the case in the new new new new ු .\n",
      "\n",
      "#3\n",
      "Source: Zwei Anlagen so nah beieinander: Absicht oder Schildbürgerstreich?\n",
      "Target: Two sets of lights so close to one another: intentional or just a silly error?\n",
      "Prediction: What is the same as the other countries : what is the same as the other countries or the other countries ?\n",
      "\n",
      "#4\n",
      "Source: Diese Frage hat Gutachs Bürgermeister gestern klar beantwortet.\n",
      "Target: Yesterday, Gutacht's Mayor gave a clear answer to this question.\n",
      "Prediction: This question has been the same issue , and the question has been made a great deal of political groups .\n",
      "\n",
      "#5\n",
      "Source: \"Die Rathausampel ist damals installiert worden, weil diese den Schulweg sichert\", erläuterte Eckert gestern.\n",
      "Target: \"At the time, the Town Hall traffic lights were installed because this was a school route,\" explained Eckert yesterday.\n",
      "Prediction: The current situation has been the same as the Party of the lays down the fact that the Bewirtschaftung ety was the case .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    samples = dataset.dataset[\"test\"][\"translation\"]\n",
    "    idx = np.random.randint(len(samples))\n",
    "    sample = samples[i]\n",
    "    print(f\"#{i+1}\")\n",
    "    print(f\"Source: {sample['de']}\")\n",
    "    print(f\"Target: {sample['en']}\")\n",
    "    print(f\"Prediction: {transformer.translate(sample['de'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 14302156, tot: 14303264, percentage: 99.99%\n",
      "count: 14339828, tot: 14340777, percentage: 99.99%\n"
     ]
    }
   ],
   "source": [
    "for name in [\"src_len\", \"tgt_len\"]:\n",
    "    len_list = dataset.dataset[\"train\"][name]\n",
    "    tot = sum(len_list)\n",
    "    count = 0\n",
    "    for num in len_list:\n",
    "        if num <= 256:\n",
    "            count += num\n",
    "    print(f\"count: {count}, tot: {tot}, percentage: {count/tot*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FSMTForConditionalGeneration were not initialized from the model checkpoint at facebook/wmt19-de-en and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is great, isn't it?\n"
     ]
    }
   ],
   "source": [
    "from transformers import FSMTForConditionalGeneration, FSMTTokenizer\n",
    "mname = \"facebook/wmt19-de-en\"\n",
    "tokenizer = FSMTTokenizer.from_pretrained(mname)\n",
    "model = FSMTForConditionalGeneration.from_pretrained(mname)\n",
    "\n",
    "input = \"Maschinelles Lernen ist großartig, oder?\"\n",
    "input_ids = tokenizer.encode(input, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids)\n",
    "decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'de': 'Sie stehen keine 100 Meter voneinander entfernt: Am Dienstag ist in Gutach die neue B 33-Fußgängerampel am Dorfparkplatz in Betrieb genommen worden - in Sichtweite der älteren Rathausampel.',\n",
       "  'en': 'They are not even 100 metres apart: On Tuesday, the new B 33 pedestrian lights in Dorfparkplatz in Gutach became operational - within view of the existing Town Hall traffic lights.'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset[\"test\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They are less than 100 metres apart: on Tuesday, the new B 33 pedestrian traffic light at the village car park was put into operation in Gutach - within sight of the older town hall traffic light.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(dataset.dataset[\"test\"][1][\"translation\"][\"de\"], return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids)\n",
    "decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
