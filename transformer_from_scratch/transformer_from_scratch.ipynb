{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Transformer from Attention is All You Need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  32\n",
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from dataset import Dataset\n",
    "from tokenizer import get_tokenizer\n",
    "from utils import NUM_PROC, DEVICE, free_memory, analyze_params, compare_params\n",
    "from model import *\n",
    "from transformer import Transformer\n",
    "\n",
    "print(\"Number of processors: \", NUM_PROC)\n",
    "print(\"Device: \", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer from Scratch\n",
    "\n",
    "Using the same hyperparameters as the base model in the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "\n",
    "Byte-Pair Encoding with shared (English + German) vocabulary of 37000 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer from ../tokenizer-wmt14-de-en.json\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer(name=\"wmt14\", language=\"de-en\", vocab_size=37000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset is downloaded at ~/.cache/huggingface/datasets/. I've turned off dataset caching to avoid disk explosion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(name=\"wmt14\", language=\"de-en\", percentage=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e25fe9353f6441780a012acf4fe3328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/45088 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4cd45b14b864358a52369b9b15913ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ec51a45cbb44fe9fb4d84597c1984d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/3003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# about 1 minute\n",
    "dataset.tokenize(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454da276394543b78ad7cb26f419d156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/45088 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35486afd301a41f986c2423ced22f976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/45088 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440740ab8b9043fd8dd6a696d9e832dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d686d51f4d4e4f97fdb66119a15567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ed34492a1d43d2983693752c144737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c15172bfaf74293a114d99c3c3d9cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/3003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# about 5 minutes\n",
    "dataloader = {}\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    dataset.dataset[split] = dataset.dataset[split].sort(\"src_len\")\n",
    "    dataloader[split] = dataset.get_dataloader(split=split, batch_size=64, shuffle=True, max_len=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the transformer model\n",
    "model = TransformerModel(vocab_size=tokenizer.get_vocab_size()).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=512**-0.5, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda nstep: min((nstep + 1) ** -0.5, (nstep + 1) * 4000 ** -1.5))\n",
    "loss_fn = nn.CrossEntropyLoss() # could add label smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from step 774947 with learning rate 0.000050\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "load_model = \"old_model/base_100%_e11.pth\"\n",
    "epoch = int(load_model.split(\".pth\")[0].split(\"_e\")[1])\n",
    "model.load_state_dict(torch.load(load_model))\n",
    "num_steps_trained = int(4508785 / 64 * epoch)\n",
    "for _ in range(num_steps_trained):\n",
    "    scheduler.step()\n",
    "print(f\"Starting from step {num_steps_trained} with learning rate {scheduler.get_last_lr()[0]:f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   1798 MiB |  10366 MiB |  92957 GiB |  92956 GiB |\n",
      "|       from large pool |   1435 MiB |   9854 MiB |  91883 GiB |  91882 GiB |\n",
      "|       from small pool |    362 MiB |    727 MiB |   1074 GiB |   1073 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   1798 MiB |  10366 MiB |  92957 GiB |  92956 GiB |\n",
      "|       from large pool |   1435 MiB |   9854 MiB |  91883 GiB |  91882 GiB |\n",
      "|       from small pool |    362 MiB |    727 MiB |   1074 GiB |   1073 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |   1798 MiB |  10362 MiB |  92908 GiB |  92906 GiB |\n",
      "|       from large pool |   1435 MiB |   9850 MiB |  91834 GiB |  91832 GiB |\n",
      "|       from small pool |    362 MiB |    727 MiB |   1073 GiB |   1073 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   2644 MiB |  13480 MiB |   1110 GiB |   1108 GiB |\n",
      "|       from large pool |   2272 MiB |  12750 MiB |   1081 GiB |   1078 GiB |\n",
      "|       from small pool |    372 MiB |    730 MiB |     29 GiB |     29 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |    845 MiB |   2877 MiB |  70153 GiB |  70152 GiB |\n",
      "|       from large pool |    836 MiB |   2874 MiB |  69078 GiB |  69078 GiB |\n",
      "|       from small pool |      9 MiB |     11 MiB |   1074 GiB |   1074 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    1313    |    2605    |    6993 K  |    6992 K  |\n",
      "|       from large pool |     128    |     395    |    3773 K  |    3772 K  |\n",
      "|       from small pool |    1185    |    2351    |    3220 K  |    3219 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    1313    |    2605    |    6993 K  |    6992 K  |\n",
      "|       from large pool |     128    |     395    |    3773 K  |    3772 K  |\n",
      "|       from small pool |    1185    |    2351    |    3220 K  |    3219 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     224    |     541    |   35412    |   35188    |\n",
      "|       from large pool |      38    |     187    |   20181    |   20143    |\n",
      "|       from small pool |     186    |     365    |   15231    |   15045    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      56    |     151    |    3344 K  |    3344 K  |\n",
      "|       from large pool |      21    |     144    |    1382 K  |    1382 K  |\n",
      "|       from small pool |      35    |     121    |    1961 K  |    1961 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# free_memory(\"model\", \"transformer\")\n",
    "free_memory()\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the transformer wrapper\n",
    "transformer = Transformer(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue training on loaded model\n",
    "# transformer.save(\"base_100%_e00.pth\")\n",
    "for i in range(10, 20):\n",
    "    transformer.train(dataloader[\"train\"], loss_fn, optimizer, scheduler, log_file=\"train.log\")\n",
    "    transformer.save(f\"base_100%_e{i+1:02d}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: \n",
      "Accuracy: 48.0%, Avg loss: 3.466424\n"
     ]
    }
   ],
   "source": [
    "transformer.validate(dataloader[\"validation\"], loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 63082496\n",
      "\u001b[32membedding.weight\u001b[39m\n",
      "\t(37000, 512)         torch.float32\tparam =   -0.0003240 +/-   0.9999905\tgrad = None\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000179 +/-   0.0254906\tgrad = None\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0004377 +/-   0.0257921\tgrad = None\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000482 +/-   0.0254886\tgrad = None\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0018594 +/-   0.0252353\tgrad = None\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000349 +/-   0.0254972\tgrad = None\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0009199 +/-   0.0248895\tgrad = None\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000412 +/-   0.0254923\tgrad = None\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0012846 +/-   0.0244355\tgrad = None\n",
      "\u001b[32mencoder.layers.0.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.0.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.0.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =    0.0000135 +/-   0.0255137\tgrad = None\n",
      "\u001b[32mencoder.layers.0.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =    0.0001578 +/-   0.0253979\tgrad = None\n",
      "\u001b[32mencoder.layers.0.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =   -0.0000199 +/-   0.0127602\tgrad = None\n",
      "\u001b[32mencoder.layers.0.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0001488 +/-   0.0127184\tgrad = None\n",
      "\u001b[32mencoder.layers.0.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.0.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000025 +/-   0.0255411\tgrad = None\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0005485 +/-   0.0260936\tgrad = None\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000532 +/-   0.0255400\tgrad = None\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0012286 +/-   0.0249091\tgrad = None\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000349 +/-   0.0255217\tgrad = None\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0006909 +/-   0.0256784\tgrad = None\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000053 +/-   0.0255165\tgrad = None\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0004696 +/-   0.0256181\tgrad = None\n",
      "\u001b[32mencoder.layers.1.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.1.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.1.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0000707 +/-   0.0255279\tgrad = None\n",
      "\u001b[32mencoder.layers.1.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =    0.0000029 +/-   0.0251865\tgrad = None\n",
      "\u001b[32mencoder.layers.1.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =    0.0000059 +/-   0.0127565\tgrad = None\n",
      "\u001b[32mencoder.layers.1.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0005805 +/-   0.0123321\tgrad = None\n",
      "\u001b[32mencoder.layers.1.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.1.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000962 +/-   0.0255011\tgrad = None\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0018009 +/-   0.0256828\tgrad = None\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000218 +/-   0.0255245\tgrad = None\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0005005 +/-   0.0257978\tgrad = None\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000013 +/-   0.0255141\tgrad = None\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0001651 +/-   0.0252534\tgrad = None\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000093 +/-   0.0255345\tgrad = None\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000788 +/-   0.0254786\tgrad = None\n",
      "\u001b[32mencoder.layers.2.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.2.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.2.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =    0.0000093 +/-   0.0254990\tgrad = None\n",
      "\u001b[32mencoder.layers.2.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =    0.0005263 +/-   0.0256899\tgrad = None\n",
      "\u001b[32mencoder.layers.2.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =    0.0000013 +/-   0.0127624\tgrad = None\n",
      "\u001b[32mencoder.layers.2.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0004189 +/-   0.0125483\tgrad = None\n",
      "\u001b[32mencoder.layers.2.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.2.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000250 +/-   0.0254931\tgrad = None\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0015138 +/-   0.0254800\tgrad = None\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000004 +/-   0.0255323\tgrad = None\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0001882 +/-   0.0248365\tgrad = None\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000542 +/-   0.0254912\tgrad = None\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0007460 +/-   0.0251888\tgrad = None\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000163 +/-   0.0255011\tgrad = None\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0006142 +/-   0.0256698\tgrad = None\n",
      "\u001b[32mencoder.layers.3.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.3.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.3.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0000240 +/-   0.0254991\tgrad = None\n",
      "\u001b[32mencoder.layers.3.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =    0.0006819 +/-   0.0247881\tgrad = None\n",
      "\u001b[32mencoder.layers.3.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =    0.0000192 +/-   0.0127533\tgrad = None\n",
      "\u001b[32mencoder.layers.3.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0007466 +/-   0.0125651\tgrad = None\n",
      "\u001b[32mencoder.layers.3.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.3.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000514 +/-   0.0255263\tgrad = None\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0006559 +/-   0.0258572\tgrad = None\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0001024 +/-   0.0255379\tgrad = None\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0003386 +/-   0.0261566\tgrad = None\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000096 +/-   0.0255271\tgrad = None\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0014981 +/-   0.0247822\tgrad = None\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000053 +/-   0.0255248\tgrad = None\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0009663 +/-   0.0255762\tgrad = None\n",
      "\u001b[32mencoder.layers.4.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.4.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.4.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0000124 +/-   0.0255057\tgrad = None\n",
      "\u001b[32mencoder.layers.4.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0004056 +/-   0.0252413\tgrad = None\n",
      "\u001b[32mencoder.layers.4.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =    0.0000192 +/-   0.0127640\tgrad = None\n",
      "\u001b[32mencoder.layers.4.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0001370 +/-   0.0128372\tgrad = None\n",
      "\u001b[32mencoder.layers.4.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.4.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000741 +/-   0.0255172\tgrad = None\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0003676 +/-   0.0257159\tgrad = None\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000155 +/-   0.0255301\tgrad = None\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0009531 +/-   0.0246019\tgrad = None\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000391 +/-   0.0254754\tgrad = None\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0007125 +/-   0.0250453\tgrad = None\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000540 +/-   0.0255358\tgrad = None\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0003668 +/-   0.0252231\tgrad = None\n",
      "\u001b[32mencoder.layers.5.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.5.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.5.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0000484 +/-   0.0255161\tgrad = None\n",
      "\u001b[32mencoder.layers.5.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0007273 +/-   0.0252978\tgrad = None\n",
      "\u001b[32mencoder.layers.5.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =   -0.0000120 +/-   0.0127639\tgrad = None\n",
      "\u001b[32mencoder.layers.5.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0010833 +/-   0.0128009\tgrad = None\n",
      "\u001b[32mencoder.layers.5.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mencoder.layers.5.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000577 +/-   0.0255341\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0010230 +/-   0.0256396\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000563 +/-   0.0255211\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0029486 +/-   0.0251160\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000118 +/-   0.0255277\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0002141 +/-   0.0246790\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000638 +/-   0.0255202\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0010681 +/-   0.0260107\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000479 +/-   0.0255156\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0004437 +/-   0.0243861\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000553 +/-   0.0255367\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0014886 +/-   0.0250375\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000613 +/-   0.0255151\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0011980 +/-   0.0253231\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000174 +/-   0.0255486\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0005467 +/-   0.0258228\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =    0.0000077 +/-   0.0255387\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =    0.0000291 +/-   0.0256251\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =   -0.0000002 +/-   0.0127746\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0006600 +/-   0.0131748\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.add_norm3.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.add_norm3.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000734 +/-   0.0254887\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0002678 +/-   0.0258080\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000407 +/-   0.0254934\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0003893 +/-   0.0248255\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000047 +/-   0.0255159\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0001817 +/-   0.0252087\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000431 +/-   0.0255134\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0011636 +/-   0.0249597\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000585 +/-   0.0255225\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0010999 +/-   0.0245806\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000227 +/-   0.0255077\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0001376 +/-   0.0254407\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000347 +/-   0.0255290\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0016233 +/-   0.0249202\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000269 +/-   0.0255206\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0013330 +/-   0.0263096\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0000070 +/-   0.0255397\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =    0.0004171 +/-   0.0250930\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =   -0.0000108 +/-   0.0127521\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0000688 +/-   0.0128630\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.add_norm3.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.add_norm3.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000778 +/-   0.0255208\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0005713 +/-   0.0250789\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000672 +/-   0.0255224\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0021408 +/-   0.0246303\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000496 +/-   0.0254799\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0013742 +/-   0.0256314\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000326 +/-   0.0255094\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0004257 +/-   0.0259311\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000252 +/-   0.0255481\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0013009 +/-   0.0256729\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000797 +/-   0.0255332\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0006936 +/-   0.0252331\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000016 +/-   0.0255173\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0015624 +/-   0.0260904\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000556 +/-   0.0255177\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0000071 +/-   0.0251251\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0000474 +/-   0.0255378\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0008160 +/-   0.0258181\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =    0.0000029 +/-   0.0127586\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0005053 +/-   0.0127840\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.add_norm3.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.add_norm3.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0001317 +/-   0.0255139\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0009697 +/-   0.0247810\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000500 +/-   0.0255541\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0015862 +/-   0.0253566\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000132 +/-   0.0255003\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0005545 +/-   0.0260567\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000296 +/-   0.0255284\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0004323 +/-   0.0248501\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000016 +/-   0.0254768\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0002761 +/-   0.0255799\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000041 +/-   0.0255397\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0002997 +/-   0.0256586\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000615 +/-   0.0255280\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0023979 +/-   0.0252646\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000456 +/-   0.0255364\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0007406 +/-   0.0255300\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0000187 +/-   0.0255352\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0005350 +/-   0.0248154\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =    0.0000056 +/-   0.0127606\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0002139 +/-   0.0127253\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.add_norm3.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.add_norm3.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000090 +/-   0.0255103\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0009000 +/-   0.0256433\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000497 +/-   0.0255170\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0000153 +/-   0.0249709\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000076 +/-   0.0255185\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0011452 +/-   0.0257599\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000196 +/-   0.0255374\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0005804 +/-   0.0256367\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000373 +/-   0.0255231\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0005005 +/-   0.0257716\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000551 +/-   0.0254827\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0009260 +/-   0.0253360\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000036 +/-   0.0255544\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0002868 +/-   0.0255461\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000180 +/-   0.0255122\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0008252 +/-   0.0263169\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0000045 +/-   0.0255195\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0000067 +/-   0.0253988\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =    0.0000114 +/-   0.0127512\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0004153 +/-   0.0125850\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.add_norm3.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.add_norm3.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0001651 +/-   0.0255503\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0017191 +/-   0.0255997\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000267 +/-   0.0254849\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0013704 +/-   0.0253869\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000168 +/-   0.0255345\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0007670 +/-   0.0248480\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000073 +/-   0.0254988\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0025324 +/-   0.0258126\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000326 +/-   0.0255418\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0008670 +/-   0.0255814\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000122 +/-   0.0254997\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0005028 +/-   0.0255997\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000063 +/-   0.0255584\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0012656 +/-   0.0248843\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000390 +/-   0.0254846\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0001443 +/-   0.0256283\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =    0.0000114 +/-   0.0255152\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =    0.0008320 +/-   0.0255067\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =   -0.0000130 +/-   0.0127599\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0004267 +/-   0.0131226\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.add_norm3.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0000000 +/-   0.0000000\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.add_norm3.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000000 +/-   0.0000000\tgrad = None\n"
     ]
    }
   ],
   "source": [
    "module = TransformerModel(37000)\n",
    "analyze_params(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that PyTorch initializes its layers with\n",
    "\n",
    "-   Embedding:  $0\\pm 1$\n",
    "\n",
    "-   Linear: $0\\pm 1 / \\sqrt{3 d_{\\rm in}}$\n",
    "\n",
    "-   LayerNorm: $\\gamma = 1,\\ \\beta = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 63082496\n",
      "\u001b[32membedding.weight\u001b[39m\n",
      "\t(37000, 512)         torch.float32\tparam =   -0.0002504 +/-   1.0052953\tgrad = None\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000068 +/-   0.0819763\tgrad = None\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0054485 +/-   0.0992457\tgrad = None\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000100 +/-   0.0823582\tgrad = None\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0004820 +/-   0.0260727\tgrad = None\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000113 +/-   0.0239310\tgrad = None\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0023827 +/-   0.0848971\tgrad = None\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000129 +/-   0.0146966\tgrad = None\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0011573 +/-   0.2216344\tgrad = None\n",
      "\u001b[32mencoder.layers.0.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.8936740 +/-   0.0628988\tgrad = None\n",
      "\u001b[32mencoder.layers.0.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0054915 +/-   0.4159271\tgrad = None\n",
      "\u001b[32mencoder.layers.0.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =    0.0001402 +/-   0.0915046\tgrad = None\n",
      "\u001b[32mencoder.layers.0.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0857362 +/-   0.0502016\tgrad = None\n",
      "\u001b[32mencoder.layers.0.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =    0.0000124 +/-   0.0837758\tgrad = None\n",
      "\u001b[32mencoder.layers.0.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0003204 +/-   0.0698855\tgrad = None\n",
      "\u001b[32mencoder.layers.0.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.5834221 +/-   0.0557154\tgrad = None\n",
      "\u001b[32mencoder.layers.0.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0005863 +/-   0.1462231\tgrad = None\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000086 +/-   0.0642030\tgrad = None\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0061158 +/-   0.0957441\tgrad = None\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000136 +/-   0.0649981\tgrad = None\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0015114 +/-   0.0251881\tgrad = None\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000431 +/-   0.0560369\tgrad = None\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0010549 +/-   0.0545302\tgrad = None\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000325 +/-   0.0514130\tgrad = None\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0010575 +/-   0.1450417\tgrad = None\n",
      "\u001b[32mencoder.layers.1.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.9344158 +/-   0.0948937\tgrad = None\n",
      "\u001b[32mencoder.layers.1.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0015696 +/-   0.3515738\tgrad = None\n",
      "\u001b[32mencoder.layers.1.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0000752 +/-   0.0929951\tgrad = None\n",
      "\u001b[32mencoder.layers.1.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0687119 +/-   0.0350882\tgrad = None\n",
      "\u001b[32mencoder.layers.1.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =   -0.0001340 +/-   0.0864995\tgrad = None\n",
      "\u001b[32mencoder.layers.1.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0004333 +/-   0.1319921\tgrad = None\n",
      "\u001b[32mencoder.layers.1.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.6482537 +/-   0.1310982\tgrad = None\n",
      "\u001b[32mencoder.layers.1.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0035119 +/-   0.1192364\tgrad = None\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0001762 +/-   0.0607919\tgrad = None\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0051747 +/-   0.1066845\tgrad = None\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000387 +/-   0.0603439\tgrad = None\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0007699 +/-   0.0255886\tgrad = None\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0001378 +/-   0.0568169\tgrad = None\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0004135 +/-   0.0293154\tgrad = None\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0001456 +/-   0.0534890\tgrad = None\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0005468 +/-   0.1188798\tgrad = None\n",
      "\u001b[32mencoder.layers.2.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.9609084 +/-   0.1361069\tgrad = None\n",
      "\u001b[32mencoder.layers.2.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0073082 +/-   0.2653060\tgrad = None\n",
      "\u001b[32mencoder.layers.2.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0005253 +/-   0.0814674\tgrad = None\n",
      "\u001b[32mencoder.layers.2.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0787053 +/-   0.0341348\tgrad = None\n",
      "\u001b[32mencoder.layers.2.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =   -0.0002944 +/-   0.0786980\tgrad = None\n",
      "\u001b[32mencoder.layers.2.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0022486 +/-   0.1046016\tgrad = None\n",
      "\u001b[32mencoder.layers.2.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.9351686 +/-   0.1942042\tgrad = None\n",
      "\u001b[32mencoder.layers.2.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0034218 +/-   0.0524554\tgrad = None\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0001992 +/-   0.0800911\tgrad = None\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0134102 +/-   0.2013897\tgrad = None\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000018 +/-   0.0814249\tgrad = None\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0010269 +/-   0.0256730\tgrad = None\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000143 +/-   0.0444648\tgrad = None\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0008198 +/-   0.0116089\tgrad = None\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0001250 +/-   0.0435054\tgrad = None\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0003636 +/-   0.0672792\tgrad = None\n",
      "\u001b[32mencoder.layers.3.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.9785842 +/-   0.1578824\tgrad = None\n",
      "\u001b[32mencoder.layers.3.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0049700 +/-   0.1663137\tgrad = None\n",
      "\u001b[32mencoder.layers.3.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0005944 +/-   0.0750370\tgrad = None\n",
      "\u001b[32mencoder.layers.3.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0826801 +/-   0.0346597\tgrad = None\n",
      "\u001b[32mencoder.layers.3.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =   -0.0001212 +/-   0.0727013\tgrad = None\n",
      "\u001b[32mencoder.layers.3.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0006699 +/-   0.0830388\tgrad = None\n",
      "\u001b[32mencoder.layers.3.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.8742332 +/-   0.2038482\tgrad = None\n",
      "\u001b[32mencoder.layers.3.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0073187 +/-   0.0573174\tgrad = None\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000449 +/-   0.0763049\tgrad = None\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0059107 +/-   0.1075842\tgrad = None\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0001425 +/-   0.0754827\tgrad = None\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0006301 +/-   0.0267509\tgrad = None\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0001379 +/-   0.0421406\tgrad = None\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0015671 +/-   0.0316323\tgrad = None\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000697 +/-   0.0414703\tgrad = None\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0002366 +/-   0.0674811\tgrad = None\n",
      "\u001b[32mencoder.layers.4.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.9489775 +/-   0.1796839\tgrad = None\n",
      "\u001b[32mencoder.layers.4.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0139176 +/-   0.1756787\tgrad = None\n",
      "\u001b[32mencoder.layers.4.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0009550 +/-   0.0766741\tgrad = None\n",
      "\u001b[32mencoder.layers.4.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0895711 +/-   0.0444111\tgrad = None\n",
      "\u001b[32mencoder.layers.4.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =   -0.0001311 +/-   0.0769490\tgrad = None\n",
      "\u001b[32mencoder.layers.4.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0001649 +/-   0.0826342\tgrad = None\n",
      "\u001b[32mencoder.layers.4.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0222986 +/-   0.1413348\tgrad = None\n",
      "\u001b[32mencoder.layers.4.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0284286 +/-   0.0679578\tgrad = None\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0001527 +/-   0.0759139\tgrad = None\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0031603 +/-   0.1264029\tgrad = None\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0001134 +/-   0.0705852\tgrad = None\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0017148 +/-   0.0299144\tgrad = None\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000388 +/-   0.0403451\tgrad = None\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0024470 +/-   0.0445332\tgrad = None\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000643 +/-   0.0385224\tgrad = None\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0031229 +/-   0.1013852\tgrad = None\n",
      "\u001b[32mencoder.layers.5.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.8023083 +/-   0.1196050\tgrad = None\n",
      "\u001b[32mencoder.layers.5.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0065255 +/-   0.1470955\tgrad = None\n",
      "\u001b[32mencoder.layers.5.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0003919 +/-   0.0444975\tgrad = None\n",
      "\u001b[32mencoder.layers.5.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0480909 +/-   0.0392675\tgrad = None\n",
      "\u001b[32mencoder.layers.5.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =   -0.0001976 +/-   0.0424254\tgrad = None\n",
      "\u001b[32mencoder.layers.5.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0009831 +/-   0.0724154\tgrad = None\n",
      "\u001b[32mencoder.layers.5.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.4944921 +/-   0.0838676\tgrad = None\n",
      "\u001b[32mencoder.layers.5.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0087715 +/-   0.0756997\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0002577 +/-   0.0852982\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0033870 +/-   0.0911215\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000103 +/-   0.0861437\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0007645 +/-   0.0260047\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000058 +/-   0.0188168\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0006605 +/-   0.1272326\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000006 +/-   0.0153802\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0007317 +/-   0.1696475\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0496817 +/-   0.0219840\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000654 +/-   0.2008283\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000011 +/-   0.0814326\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0074692 +/-   0.2753734\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0001112 +/-   0.0787534\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0011898 +/-   0.0258360\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000925 +/-   0.0643644\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0010610 +/-   0.0164297\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000244 +/-   0.0644172\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0004819 +/-   0.0478307\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.9959538 +/-   0.0416810\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0005747 +/-   0.1943613\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =    0.0000492 +/-   0.0946897\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0581790 +/-   0.0415870\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =   -0.0000806 +/-   0.0912770\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0003168 +/-   0.0555473\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.add_norm3.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.6354033 +/-   0.0648422\tgrad = None\n",
      "\u001b[32mdecoder.layers.0.add_norm3.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0162028 +/-   0.0656366\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0001419 +/-   0.0655010\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0170892 +/-   0.2057868\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0001355 +/-   0.0651055\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0009992 +/-   0.0260311\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000747 +/-   0.0519422\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0023335 +/-   0.0359276\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000202 +/-   0.0463098\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0009967 +/-   0.0590738\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0431733 +/-   0.0591135\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0019183 +/-   0.2243783\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000433 +/-   0.0913360\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0026398 +/-   0.1043827\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000240 +/-   0.0883346\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0012228 +/-   0.0292404\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0001097 +/-   0.0802373\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0007476 +/-   0.0328496\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000528 +/-   0.0809621\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0014157 +/-   0.0693689\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.9628174 +/-   0.0967496\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0133343 +/-   0.2536870\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0003101 +/-   0.0954203\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0412019 +/-   0.0334245\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =   -0.0004093 +/-   0.0907425\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0045825 +/-   0.1701269\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.add_norm3.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.6061767 +/-   0.0681259\tgrad = None\n",
      "\u001b[32mdecoder.layers.1.add_norm3.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0212284 +/-   0.0714095\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000944 +/-   0.0659091\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0010327 +/-   0.1217975\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000304 +/-   0.0656764\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000442 +/-   0.0275005\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000465 +/-   0.0577384\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000258 +/-   0.0267093\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000135 +/-   0.0533266\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0006804 +/-   0.0308564\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.9898975 +/-   0.0678242\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0014985 +/-   0.2101439\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000474 +/-   0.0818952\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000211 +/-   0.0916144\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000370 +/-   0.0804350\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0004495 +/-   0.0284159\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000930 +/-   0.0828189\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0000625 +/-   0.0168805\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000504 +/-   0.0814826\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0000296 +/-   0.0439937\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.9472708 +/-   0.0959502\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0223710 +/-   0.2249862\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0009783 +/-   0.0860684\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0436391 +/-   0.0329485\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =    0.0000395 +/-   0.0852658\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0021371 +/-   0.1627833\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.add_norm3.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.7151886 +/-   0.0660449\tgrad = None\n",
      "\u001b[32mdecoder.layers.2.add_norm3.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0142106 +/-   0.1069706\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0002855 +/-   0.0702142\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0076658 +/-   0.1018863\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000414 +/-   0.0705962\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0024096 +/-   0.0390952\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000182 +/-   0.0559090\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0007278 +/-   0.0298965\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000028 +/-   0.0490566\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0012198 +/-   0.0239544\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.9585185 +/-   0.0765375\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0030476 +/-   0.1572865\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000299 +/-   0.0882101\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0008492 +/-   0.1384284\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000900 +/-   0.0888987\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0005026 +/-   0.0287722\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0001618 +/-   0.0982944\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0005619 +/-   0.0158296\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000636 +/-   0.0936886\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0002479 +/-   0.0316867\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.9441949 +/-   0.0899446\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0053324 +/-   0.2118947\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0012388 +/-   0.0766670\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0582492 +/-   0.0423908\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =   -0.0000004 +/-   0.0801031\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0023934 +/-   0.1493899\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.add_norm3.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.8291425 +/-   0.0526092\tgrad = None\n",
      "\u001b[32mdecoder.layers.3.add_norm3.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0474955 +/-   0.0904932\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000800 +/-   0.0629573\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0017293 +/-   0.0887405\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000221 +/-   0.0602912\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0015836 +/-   0.0253339\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0001810 +/-   0.0605843\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0007591 +/-   0.0294036\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000156 +/-   0.0516357\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0009315 +/-   0.0218350\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.9561525 +/-   0.0322017\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0004945 +/-   0.2008632\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000145 +/-   0.0922111\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0016889 +/-   0.0903508\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000805 +/-   0.0905011\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0009539 +/-   0.0329131\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000009 +/-   0.0957131\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0005848 +/-   0.0137445\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000469 +/-   0.0929544\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0002985 +/-   0.0243482\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.9364974 +/-   0.0671418\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0118407 +/-   0.2247996\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0016229 +/-   0.0642441\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0454229 +/-   0.0416064\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =   -0.0000290 +/-   0.0720965\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0012751 +/-   0.1036974\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.add_norm3.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    1.0050170 +/-   0.0662543\tgrad = None\n",
      "\u001b[32mdecoder.layers.4.add_norm3.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0450367 +/-   0.1040524\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000187 +/-   0.0650680\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0009965 +/-   0.0655352\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0001052 +/-   0.0624723\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0004037 +/-   0.0267851\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000624 +/-   0.0315060\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0017167 +/-   0.0310314\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000033 +/-   0.0192292\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0003894 +/-   0.0185254\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.add_norm1.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.9087412 +/-   0.1207328\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.add_norm1.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0053733 +/-   0.3115388\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000322 +/-   0.1118522\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0002293 +/-   0.0427754\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =   -0.0000410 +/-   0.0940721\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0006581 +/-   0.0338348\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000527 +/-   0.0773700\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0000126 +/-   0.0115635\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.linear.weight\u001b[39m\n",
      "\t(512, 512)           torch.float32\tparam =    0.0000139 +/-   0.0795880\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.linear.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0008469 +/-   0.0317333\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.add_norm2.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.8240629 +/-   0.1558917\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.add_norm2.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0008339 +/-   0.2922931\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.feed_forward.linear1.weight\u001b[39m\n",
      "\t(2048, 512)          torch.float32\tparam =   -0.0004169 +/-   0.0366533\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.feed_forward.linear1.bias\u001b[39m\n",
      "\t(2048,)              torch.float32\tparam =   -0.0101399 +/-   0.0259832\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.feed_forward.linear2.weight\u001b[39m\n",
      "\t(512, 2048)          torch.float32\tparam =   -0.0000310 +/-   0.0372562\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.feed_forward.linear2.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.0005097 +/-   0.0371605\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.add_norm3.norm.weight\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =    0.5811455 +/-   0.1018436\tgrad = None\n",
      "\u001b[32mdecoder.layers.5.add_norm3.norm.bias\u001b[39m\n",
      "\t(512,)               torch.float32\tparam =   -0.0166612 +/-   0.1207467\tgrad = None\n"
     ]
    }
   ],
   "source": [
    "analyze_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Shift over Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32membedding.weight\u001b[39m\n",
      "(37000, 512)        \tparam1 =   -0.0002504 +/-   1.0052953\tparam2 =   -0.0002411 +/-   0.9999496\tdiff(rms) =   0.1056992\tdiff(max) =   0.8115359\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000068 +/-   0.0819763\tparam2 =    0.0000490 +/-   0.0255153\tdiff(rms) =   0.0778650\tdiff(max) =   0.3792256\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0054485 +/-   0.0992457\tparam2 =   -0.0018342 +/-   0.0252954\tdiff(rms) =   0.0979231\tdiff(max) =   0.2868303\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000100 +/-   0.0823582\tparam2 =   -0.0000158 +/-   0.0255332\tdiff(rms) =   0.0782432\tdiff(max) =   0.3995680\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0004820 +/-   0.0260727\tparam2 =   -0.0005781 +/-   0.0258791\tdiff(rms) =   0.0031696\tdiff(max) =   0.0114387\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000113 +/-   0.0239310\tparam2 =   -0.0000123 +/-   0.0255196\tdiff(rms) =   0.0262621\tdiff(max) =   0.1513278\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0023827 +/-   0.0848971\tparam2 =   -0.0009154 +/-   0.0259504\tdiff(rms) =   0.0792421\tdiff(max) =   0.9716671\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000129 +/-   0.0146966\tparam2 =   -0.0000789 +/-   0.0255142\tdiff(rms) =   0.0290200\tdiff(max) =   0.2649632\n",
      "\u001b[32mencoder.layers.0.multi_head_attention.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0011573 +/-   0.2216344\tparam2 =    0.0008269 +/-   0.0259669\tdiff(rms) =   0.2206213\tdiff(max) =   0.9118223\n",
      "\u001b[32mencoder.layers.0.add_norm1.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.8936740 +/-   0.0628988\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.1235374\tdiff(max) =   0.3124251\n",
      "\u001b[32mencoder.layers.0.add_norm1.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0054915 +/-   0.4159271\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.4159633\tdiff(max) =   2.0953300\n",
      "\u001b[32mencoder.layers.0.feed_forward.linear1.weight\u001b[39m\n",
      "(2048, 512)         \tparam1 =    0.0001402 +/-   0.0915046\tparam2 =    0.0000479 +/-   0.0255065\tdiff(rms) =   0.0887445\tdiff(max) =   0.4774628\n",
      "\u001b[32mencoder.layers.0.feed_forward.linear1.bias\u001b[39m\n",
      "(2048,)             \tparam1 =   -0.0857362 +/-   0.0502016\tparam2 =   -0.0003175 +/-   0.0253200\tdiff(rms) =   0.0955952\tdiff(max) =   0.2418970\n",
      "\u001b[32mencoder.layers.0.feed_forward.linear2.weight\u001b[39m\n",
      "(512, 2048)         \tparam1 =    0.0000124 +/-   0.0837758\tparam2 =   -0.0000206 +/-   0.0127462\tdiff(rms) =   0.0830187\tdiff(max) =   1.1435740\n",
      "\u001b[32mencoder.layers.0.feed_forward.linear2.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0003204 +/-   0.0698855\tparam2 =    0.0004930 +/-   0.0128379\tdiff(rms) =   0.0694330\tdiff(max) =   0.2037257\n",
      "\u001b[32mencoder.layers.0.add_norm2.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.5834221 +/-   0.0557154\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.4202872\tdiff(max) =   0.7332191\n",
      "\u001b[32mencoder.layers.0.add_norm2.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0005863 +/-   0.1462231\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.1462243\tdiff(max) =   0.5473566\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000086 +/-   0.0642030\tparam2 =    0.0000356 +/-   0.0255656\tdiff(rms) =   0.0626193\tdiff(max) =   0.2914012\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0061158 +/-   0.0957441\tparam2 =    0.0011256 +/-   0.0257431\tdiff(rms) =   0.0889993\tdiff(max) =   0.3228559\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000136 +/-   0.0649981\tparam2 =   -0.0000878 +/-   0.0255174\tdiff(rms) =   0.0626284\tdiff(max) =   0.3443642\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0015114 +/-   0.0251881\tparam2 =    0.0018430 +/-   0.0249017\tdiff(rms) =   0.0045810\tdiff(max) =   0.0146503\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000431 +/-   0.0560369\tparam2 =   -0.0000311 +/-   0.0254982\tdiff(rms) =   0.0546339\tdiff(max) =   0.2660092\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0010549 +/-   0.0545302\tparam2 =    0.0000701 +/-   0.0250935\tdiff(rms) =   0.0415574\tdiff(max) =   0.2872926\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000325 +/-   0.0514130\tparam2 =   -0.0000734 +/-   0.0255219\tdiff(rms) =   0.0503721\tdiff(max) =   0.5611982\n",
      "\u001b[32mencoder.layers.1.multi_head_attention.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0010575 +/-   0.1450417\tparam2 =   -0.0004200 +/-   0.0258132\tdiff(rms) =   0.1397521\tdiff(max) =   0.7778393\n",
      "\u001b[32mencoder.layers.1.add_norm1.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.9344158 +/-   0.0948937\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.1153521\tdiff(max) =   0.9007488\n",
      "\u001b[32mencoder.layers.1.add_norm1.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0015696 +/-   0.3515738\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.3515773\tdiff(max) =   1.9550171\n",
      "\u001b[32mencoder.layers.1.feed_forward.linear1.weight\u001b[39m\n",
      "(2048, 512)         \tparam1 =   -0.0000752 +/-   0.0929951\tparam2 =   -0.0000541 +/-   0.0255234\tdiff(rms) =   0.0901204\tdiff(max) =   0.5077578\n",
      "\u001b[32mencoder.layers.1.feed_forward.linear1.bias\u001b[39m\n",
      "(2048,)             \tparam1 =   -0.0687119 +/-   0.0350882\tparam2 =    0.0001933 +/-   0.0260403\tdiff(rms) =   0.0725726\tdiff(max) =   0.1338273\n",
      "\u001b[32mencoder.layers.1.feed_forward.linear2.weight\u001b[39m\n",
      "(512, 2048)         \tparam1 =   -0.0001340 +/-   0.0864995\tparam2 =    0.0000027 +/-   0.0127573\tdiff(rms) =   0.0857016\tdiff(max) =   2.1469822\n",
      "\u001b[32mencoder.layers.1.feed_forward.linear2.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0004333 +/-   0.1319921\tparam2 =   -0.0003360 +/-   0.0127111\tdiff(rms) =   0.1324315\tdiff(max) =   0.9423341\n",
      "\u001b[32mencoder.layers.1.add_norm2.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.6482537 +/-   0.1310982\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.3753828\tdiff(max) =   0.8639851\n",
      "\u001b[32mencoder.layers.1.add_norm2.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0035119 +/-   0.1192364\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.1192881\tdiff(max) =   0.7746196\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0001762 +/-   0.0607919\tparam2 =   -0.0000875 +/-   0.0255234\tdiff(rms) =   0.0586321\tdiff(max) =   0.3193993\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0051747 +/-   0.1066845\tparam2 =    0.0005265 +/-   0.0254417\tdiff(rms) =   0.1006006\tdiff(max) =   0.4781653\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000387 +/-   0.0603439\tparam2 =    0.0000042 +/-   0.0254750\tdiff(rms) =   0.0577139\tdiff(max) =   0.6298881\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0007699 +/-   0.0255886\tparam2 =   -0.0007656 +/-   0.0252958\tdiff(rms) =   0.0041814\tdiff(max) =   0.0221474\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0001378 +/-   0.0568169\tparam2 =    0.0000688 +/-   0.0254920\tdiff(rms) =   0.0555958\tdiff(max) =   0.3405137\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0004135 +/-   0.0293154\tparam2 =   -0.0005294 +/-   0.0263720\tdiff(rms) =   0.0166042\tdiff(max) =   0.0702410\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0001456 +/-   0.0534890\tparam2 =   -0.0000908 +/-   0.0255243\tdiff(rms) =   0.0533853\tdiff(max) =   0.2935353\n",
      "\u001b[32mencoder.layers.2.multi_head_attention.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0005468 +/-   0.1188798\tparam2 =   -0.0014660 +/-   0.0253747\tdiff(rms) =   0.1156764\tdiff(max) =   0.5523315\n",
      "\u001b[32mencoder.layers.2.add_norm1.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.9609084 +/-   0.1361069\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.1416095\tdiff(max) =   0.4406720\n",
      "\u001b[32mencoder.layers.2.add_norm1.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0073082 +/-   0.2653060\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.2654067\tdiff(max) =   1.1228999\n",
      "\u001b[32mencoder.layers.2.feed_forward.linear1.weight\u001b[39m\n",
      "(2048, 512)         \tparam1 =   -0.0005253 +/-   0.0814674\tparam2 =   -0.0000260 +/-   0.0255173\tdiff(rms) =   0.0782688\tdiff(max) =   0.5779500\n",
      "\u001b[32mencoder.layers.2.feed_forward.linear1.bias\u001b[39m\n",
      "(2048,)             \tparam1 =   -0.0787053 +/-   0.0341348\tparam2 =   -0.0000279 +/-   0.0260821\tdiff(rms) =   0.0818566\tdiff(max) =   0.1584506\n",
      "\u001b[32mencoder.layers.2.feed_forward.linear2.weight\u001b[39m\n",
      "(512, 2048)         \tparam1 =   -0.0002944 +/-   0.0786980\tparam2 =   -0.0000357 +/-   0.0127613\tdiff(rms) =   0.0777739\tdiff(max) =   4.8635521\n",
      "\u001b[32mencoder.layers.2.feed_forward.linear2.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0022486 +/-   0.1046016\tparam2 =   -0.0001049 +/-   0.0125752\tdiff(rms) =   0.1045282\tdiff(max) =   0.7190627\n",
      "\u001b[32mencoder.layers.2.add_norm2.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.9351686 +/-   0.1942042\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.2047398\tdiff(max) =   0.9578809\n",
      "\u001b[32mencoder.layers.2.add_norm2.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0034218 +/-   0.0524554\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.0525669\tdiff(max) =   0.6687019\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0001992 +/-   0.0800911\tparam2 =   -0.0000378 +/-   0.0254768\tdiff(rms) =   0.0761138\tdiff(max) =   0.3953544\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0134102 +/-   0.2013897\tparam2 =   -0.0005552 +/-   0.0252300\tdiff(rms) =   0.1975510\tdiff(max) =   0.4426419\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000018 +/-   0.0814249\tparam2 =    0.0000035 +/-   0.0255397\tdiff(rms) =   0.0773933\tdiff(max) =   0.3946754\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0010269 +/-   0.0256730\tparam2 =    0.0010824 +/-   0.0256269\tdiff(rms) =   0.0041923\tdiff(max) =   0.0197095\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000143 +/-   0.0444648\tparam2 =   -0.0000777 +/-   0.0255096\tdiff(rms) =   0.0446478\tdiff(max) =   0.2423710\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0008198 +/-   0.0116089\tparam2 =   -0.0012998 +/-   0.0256656\tdiff(rms) =   0.0187165\tdiff(max) =   0.0426182\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0001250 +/-   0.0435054\tparam2 =    0.0000925 +/-   0.0255402\tdiff(rms) =   0.0450370\tdiff(max) =   1.2168785\n",
      "\u001b[32mencoder.layers.3.multi_head_attention.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0003636 +/-   0.0672792\tparam2 =   -0.0004628 +/-   0.0263643\tdiff(rms) =   0.0680782\tdiff(max) =   0.5603145\n",
      "\u001b[32mencoder.layers.3.add_norm1.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.9785842 +/-   0.1578824\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.1593283\tdiff(max) =   0.6866182\n",
      "\u001b[32mencoder.layers.3.add_norm1.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0049700 +/-   0.1663137\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.1663880\tdiff(max) =   1.1442229\n",
      "\u001b[32mencoder.layers.3.feed_forward.linear1.weight\u001b[39m\n",
      "(2048, 512)         \tparam1 =   -0.0005944 +/-   0.0750370\tparam2 =    0.0000087 +/-   0.0255236\tdiff(rms) =   0.0717021\tdiff(max) =   0.6174724\n",
      "\u001b[32mencoder.layers.3.feed_forward.linear1.bias\u001b[39m\n",
      "(2048,)             \tparam1 =   -0.0826801 +/-   0.0346597\tparam2 =   -0.0001344 +/-   0.0255419\tdiff(rms) =   0.0860553\tdiff(max) =   0.3349932\n",
      "\u001b[32mencoder.layers.3.feed_forward.linear2.weight\u001b[39m\n",
      "(512, 2048)         \tparam1 =   -0.0001212 +/-   0.0727013\tparam2 =    0.0000196 +/-   0.0127547\tdiff(rms) =   0.0716961\tdiff(max) =   4.4589601\n",
      "\u001b[32mencoder.layers.3.feed_forward.linear2.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0006699 +/-   0.0830388\tparam2 =    0.0002459 +/-   0.0123447\tdiff(rms) =   0.0819990\tdiff(max) =   0.3524116\n",
      "\u001b[32mencoder.layers.3.add_norm2.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.8742332 +/-   0.2038482\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.2395232\tdiff(max) =   0.9389995\n",
      "\u001b[32mencoder.layers.3.add_norm2.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0073187 +/-   0.0573174\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.0577827\tdiff(max) =   0.4533247\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000449 +/-   0.0763049\tparam2 =   -0.0000338 +/-   0.0255089\tdiff(rms) =   0.0722615\tdiff(max) =   0.3815594\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0059107 +/-   0.1075842\tparam2 =   -0.0011726 +/-   0.0255226\tdiff(rms) =   0.1025271\tdiff(max) =   0.2715653\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0001425 +/-   0.0754827\tparam2 =   -0.0000423 +/-   0.0254905\tdiff(rms) =   0.0714141\tdiff(max) =   0.5185364\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0006301 +/-   0.0267509\tparam2 =    0.0009249 +/-   0.0255440\tdiff(rms) =   0.0089065\tdiff(max) =   0.0602488\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0001379 +/-   0.0421406\tparam2 =   -0.0000599 +/-   0.0255371\tdiff(rms) =   0.0427903\tdiff(max) =   0.2416272\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0015671 +/-   0.0316323\tparam2 =   -0.0004837 +/-   0.0254539\tdiff(rms) =   0.0187239\tdiff(max) =   0.0667777\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000697 +/-   0.0414703\tparam2 =   -0.0000641 +/-   0.0255536\tdiff(rms) =   0.0439091\tdiff(max) =   0.3145693\n",
      "\u001b[32mencoder.layers.4.multi_head_attention.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0002366 +/-   0.0674811\tparam2 =   -0.0015286 +/-   0.0257880\tdiff(rms) =   0.0678501\tdiff(max) =   0.5827208\n",
      "\u001b[32mencoder.layers.4.add_norm1.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.9489775 +/-   0.1796839\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.1867876\tdiff(max) =   1.5057750\n",
      "\u001b[32mencoder.layers.4.add_norm1.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0139176 +/-   0.1756787\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.1762291\tdiff(max) =   0.9048525\n",
      "\u001b[32mencoder.layers.4.feed_forward.linear1.weight\u001b[39m\n",
      "(2048, 512)         \tparam1 =   -0.0009550 +/-   0.0766741\tparam2 =    0.0000286 +/-   0.0255034\tdiff(rms) =   0.0737070\tdiff(max) =   0.4936097\n",
      "\u001b[32mencoder.layers.4.feed_forward.linear1.bias\u001b[39m\n",
      "(2048,)             \tparam1 =   -0.0895711 +/-   0.0444111\tparam2 =   -0.0000978 +/-   0.0250859\tdiff(rms) =   0.0964329\tdiff(max) =   0.4052405\n",
      "\u001b[32mencoder.layers.4.feed_forward.linear2.weight\u001b[39m\n",
      "(512, 2048)         \tparam1 =   -0.0001311 +/-   0.0769490\tparam2 =   -0.0000002 +/-   0.0127605\tdiff(rms) =   0.0760969\tdiff(max) =   3.6794882\n",
      "\u001b[32mencoder.layers.4.feed_forward.linear2.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0001649 +/-   0.0826342\tparam2 =   -0.0002240 +/-   0.0119733\tdiff(rms) =   0.0830366\tdiff(max) =   0.2566624\n",
      "\u001b[32mencoder.layers.4.add_norm2.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    1.0222986 +/-   0.1413348\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.1430830\tdiff(max) =   0.9022272\n",
      "\u001b[32mencoder.layers.4.add_norm2.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0284286 +/-   0.0679578\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.0736644\tdiff(max) =   0.2973575\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0001527 +/-   0.0759139\tparam2 =   -0.0000087 +/-   0.0255192\tdiff(rms) =   0.0718966\tdiff(max) =   0.3705554\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0031603 +/-   0.1264029\tparam2 =   -0.0000533 +/-   0.0261149\tdiff(rms) =   0.1235389\tdiff(max) =   0.4008032\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0001134 +/-   0.0705852\tparam2 =    0.0000290 +/-   0.0255191\tdiff(rms) =   0.0662528\tdiff(max) =   0.4690391\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0017148 +/-   0.0299144\tparam2 =   -0.0018463 +/-   0.0247713\tdiff(rms) =   0.0186311\tdiff(max) =   0.1573283\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000388 +/-   0.0403451\tparam2 =    0.0000223 +/-   0.0255263\tdiff(rms) =   0.0411236\tdiff(max) =   0.2944030\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0024470 +/-   0.0445332\tparam2 =   -0.0015330 +/-   0.0248070\tdiff(rms) =   0.0348645\tdiff(max) =   0.1856114\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000643 +/-   0.0385224\tparam2 =   -0.0000972 +/-   0.0255029\tdiff(rms) =   0.0417229\tdiff(max) =   1.4564610\n",
      "\u001b[32mencoder.layers.5.multi_head_attention.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0031229 +/-   0.1013852\tparam2 =    0.0005635 +/-   0.0260101\tdiff(rms) =   0.0982496\tdiff(max) =   1.2267714\n",
      "\u001b[32mencoder.layers.5.add_norm1.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.8023083 +/-   0.1196050\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.2310570\tdiff(max) =   1.1455078\n",
      "\u001b[32mencoder.layers.5.add_norm1.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0065255 +/-   0.1470955\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.1472401\tdiff(max) =   1.3150027\n",
      "\u001b[32mencoder.layers.5.feed_forward.linear1.weight\u001b[39m\n",
      "(2048, 512)         \tparam1 =   -0.0003919 +/-   0.0444975\tparam2 =   -0.0000128 +/-   0.0255027\tdiff(rms) =   0.0378679\tdiff(max) =   0.4548466\n",
      "\u001b[32mencoder.layers.5.feed_forward.linear1.bias\u001b[39m\n",
      "(2048,)             \tparam1 =   -0.0480909 +/-   0.0392675\tparam2 =    0.0004783 +/-   0.0251294\tdiff(rms) =   0.0572739\tdiff(max) =   0.3676293\n",
      "\u001b[32mencoder.layers.5.feed_forward.linear2.weight\u001b[39m\n",
      "(512, 2048)         \tparam1 =   -0.0001976 +/-   0.0424254\tparam2 =    0.0000055 +/-   0.0127618\tdiff(rms) =   0.0407338\tdiff(max) =   4.8153214\n",
      "\u001b[32mencoder.layers.5.feed_forward.linear2.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0009831 +/-   0.0724154\tparam2 =    0.0000283 +/-   0.0129838\tdiff(rms) =   0.0728632\tdiff(max) =   1.0471501\n",
      "\u001b[32mencoder.layers.5.add_norm2.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.4944921 +/-   0.0838676\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.5124178\tdiff(max) =   0.9439256\n",
      "\u001b[32mencoder.layers.5.add_norm2.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0087715 +/-   0.0756997\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.0762062\tdiff(max) =   0.9514453\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0002577 +/-   0.0852982\tparam2 =   -0.0000220 +/-   0.0255041\tdiff(rms) =   0.0813803\tdiff(max) =   0.3697639\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0033870 +/-   0.0911215\tparam2 =   -0.0004497 +/-   0.0252931\tdiff(rms) =   0.0888278\tdiff(max) =   0.3333199\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000103 +/-   0.0861437\tparam2 =   -0.0000665 +/-   0.0255371\tdiff(rms) =   0.0822661\tdiff(max) =   0.3631602\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0007645 +/-   0.0260047\tparam2 =    0.0008573 +/-   0.0257511\tdiff(rms) =   0.0027665\tdiff(max) =   0.0077804\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000058 +/-   0.0188168\tparam2 =    0.0001325 +/-   0.0255374\tdiff(rms) =   0.0298752\tdiff(max) =   0.1283379\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0006605 +/-   0.1272326\tparam2 =    0.0003427 +/-   0.0259124\tdiff(rms) =   0.1236205\tdiff(max) =   0.5864893\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000006 +/-   0.0153802\tparam2 =   -0.0000082 +/-   0.0255158\tdiff(rms) =   0.0296866\tdiff(max) =   0.1135062\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention1.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0007317 +/-   0.1696475\tparam2 =    0.0006841 +/-   0.0246960\tdiff(rms) =   0.1672476\tdiff(max) =   0.5731642\n",
      "\u001b[32mdecoder.layers.0.add_norm1.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    1.0496817 +/-   0.0219840\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.0543283\tdiff(max) =   0.1101779\n",
      "\u001b[32mdecoder.layers.0.add_norm1.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0000654 +/-   0.2008283\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.2008284\tdiff(max) =   0.8011115\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000011 +/-   0.0814326\tparam2 =    0.0000469 +/-   0.0255163\tdiff(rms) =   0.0776709\tdiff(max) =   0.4460876\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0074692 +/-   0.2753734\tparam2 =    0.0008859 +/-   0.0251539\tdiff(rms) =   0.2717972\tdiff(max) =   0.7208395\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0001112 +/-   0.0787534\tparam2 =   -0.0000481 +/-   0.0254869\tdiff(rms) =   0.0743004\tdiff(max) =   0.3599301\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0011898 +/-   0.0258360\tparam2 =    0.0008658 +/-   0.0254531\tdiff(rms) =   0.0054782\tdiff(max) =   0.0390340\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000925 +/-   0.0643644\tparam2 =   -0.0000288 +/-   0.0255324\tdiff(rms) =   0.0613457\tdiff(max) =   0.3597467\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0010610 +/-   0.0164297\tparam2 =   -0.0015309 +/-   0.0258971\tdiff(rms) =   0.0266957\tdiff(max) =   0.1020741\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000244 +/-   0.0644172\tparam2 =    0.0000244 +/-   0.0254864\tdiff(rms) =   0.0643747\tdiff(max) =   0.3224852\n",
      "\u001b[32mdecoder.layers.0.multi_head_attention2.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0004819 +/-   0.0478307\tparam2 =    0.0004874 +/-   0.0260358\tdiff(rms) =   0.0501214\tdiff(max) =   0.1878384\n",
      "\u001b[32mdecoder.layers.0.add_norm2.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.9959538 +/-   0.0416810\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.0418769\tdiff(max) =   0.2770243\n",
      "\u001b[32mdecoder.layers.0.add_norm2.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0005747 +/-   0.1943613\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.1943621\tdiff(max) =   0.7858535\n",
      "\u001b[32mdecoder.layers.0.feed_forward.linear1.weight\u001b[39m\n",
      "(2048, 512)         \tparam1 =    0.0000492 +/-   0.0946897\tparam2 =    0.0000103 +/-   0.0255221\tdiff(rms) =   0.0886478\tdiff(max) =   0.4731392\n",
      "\u001b[32mdecoder.layers.0.feed_forward.linear1.bias\u001b[39m\n",
      "(2048,)             \tparam1 =   -0.0581790 +/-   0.0415870\tparam2 =   -0.0003069 +/-   0.0259057\tdiff(rms) =   0.0664911\tdiff(max) =   0.1703196\n",
      "\u001b[32mdecoder.layers.0.feed_forward.linear2.weight\u001b[39m\n",
      "(512, 2048)         \tparam1 =   -0.0000806 +/-   0.0912770\tparam2 =   -0.0000029 +/-   0.0127579\tdiff(rms) =   0.0897162\tdiff(max) =   1.3513319\n",
      "\u001b[32mdecoder.layers.0.feed_forward.linear2.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0003168 +/-   0.0555473\tparam2 =   -0.0006806 +/-   0.0125905\tdiff(rms) =   0.0535802\tdiff(max) =   0.3270777\n",
      "\u001b[32mdecoder.layers.0.add_norm3.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.6354033 +/-   0.0648422\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.3703179\tdiff(max) =   0.9158595\n",
      "\u001b[32mdecoder.layers.0.add_norm3.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0162028 +/-   0.0656366\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.0676070\tdiff(max) =   0.8533952\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0001419 +/-   0.0655010\tparam2 =    0.0000456 +/-   0.0255052\tdiff(rms) =   0.0639090\tdiff(max) =   0.3215553\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0170892 +/-   0.2057868\tparam2 =    0.0001651 +/-   0.0249068\tdiff(rms) =   0.1989992\tdiff(max) =   1.2694683\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0001355 +/-   0.0651055\tparam2 =   -0.0000460 +/-   0.0255104\tdiff(rms) =   0.0629437\tdiff(max) =   0.3632011\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0009992 +/-   0.0260311\tparam2 =   -0.0007514 +/-   0.0249892\tdiff(rms) =   0.0073058\tdiff(max) =   0.0812470\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000747 +/-   0.0519422\tparam2 =   -0.0000660 +/-   0.0255020\tdiff(rms) =   0.0510637\tdiff(max) =   0.2455229\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0023335 +/-   0.0359276\tparam2 =   -0.0023893 +/-   0.0254876\tdiff(rms) =   0.0224166\tdiff(max) =   0.1252558\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000202 +/-   0.0463098\tparam2 =   -0.0000064 +/-   0.0255366\tdiff(rms) =   0.0474150\tdiff(max) =   0.4327941\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention1.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0009967 +/-   0.0590738\tparam2 =   -0.0018056 +/-   0.0263059\tdiff(rms) =   0.0627639\tdiff(max) =   0.3073589\n",
      "\u001b[32mdecoder.layers.1.add_norm1.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    1.0431733 +/-   0.0591135\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.0732006\tdiff(max) =   0.9309292\n",
      "\u001b[32mdecoder.layers.1.add_norm1.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0019183 +/-   0.2243783\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.2243865\tdiff(max) =   1.6319269\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000433 +/-   0.0913360\tparam2 =    0.0000301 +/-   0.0255490\tdiff(rms) =   0.0874776\tdiff(max) =   0.5484061\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0026398 +/-   0.1043827\tparam2 =   -0.0011937 +/-   0.0256595\tdiff(rms) =   0.1009326\tdiff(max) =   0.3399639\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000240 +/-   0.0883346\tparam2 =   -0.0000347 +/-   0.0255185\tdiff(rms) =   0.0841595\tdiff(max) =   0.5879701\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0012228 +/-   0.0292404\tparam2 =    0.0003798 +/-   0.0246362\tdiff(rms) =   0.0159873\tdiff(max) =   0.0896901\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0001097 +/-   0.0802373\tparam2 =   -0.0000351 +/-   0.0254788\tdiff(rms) =   0.0762624\tdiff(max) =   0.4189750\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0007476 +/-   0.0328496\tparam2 =   -0.0001122 +/-   0.0244772\tdiff(rms) =   0.0347166\tdiff(max) =   0.1337264\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000528 +/-   0.0809621\tparam2 =   -0.0000274 +/-   0.0255484\tdiff(rms) =   0.0780076\tdiff(max) =   0.6746460\n",
      "\u001b[32mdecoder.layers.1.multi_head_attention2.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0014157 +/-   0.0693689\tparam2 =   -0.0015405 +/-   0.0259888\tdiff(rms) =   0.0696388\tdiff(max) =   0.4317763\n",
      "\u001b[32mdecoder.layers.1.add_norm2.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.9628174 +/-   0.0967496\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.1036486\tdiff(max) =   1.0870733\n",
      "\u001b[32mdecoder.layers.1.add_norm2.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0133343 +/-   0.2536870\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.2540372\tdiff(max) =   2.0319288\n",
      "\u001b[32mdecoder.layers.1.feed_forward.linear1.weight\u001b[39m\n",
      "(2048, 512)         \tparam1 =   -0.0003101 +/-   0.0954203\tparam2 =   -0.0000130 +/-   0.0255229\tdiff(rms) =   0.0907580\tdiff(max) =   0.7193782\n",
      "\u001b[32mdecoder.layers.1.feed_forward.linear1.bias\u001b[39m\n",
      "(2048,)             \tparam1 =   -0.0412019 +/-   0.0334245\tparam2 =   -0.0003725 +/-   0.0256761\tdiff(rms) =   0.0462002\tdiff(max) =   0.2267430\n",
      "\u001b[32mdecoder.layers.1.feed_forward.linear2.weight\u001b[39m\n",
      "(512, 2048)         \tparam1 =   -0.0004093 +/-   0.0907425\tparam2 =   -0.0000070 +/-   0.0127504\tdiff(rms) =   0.0896758\tdiff(max) =   2.4236951\n",
      "\u001b[32mdecoder.layers.1.feed_forward.linear2.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0045825 +/-   0.1701269\tparam2 =    0.0007370 +/-   0.0128068\tdiff(rms) =   0.1690597\tdiff(max) =   1.0596236\n",
      "\u001b[32mdecoder.layers.1.add_norm3.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.6061767 +/-   0.0681259\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.3996722\tdiff(max) =   0.9373549\n",
      "\u001b[32mdecoder.layers.1.add_norm3.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0212284 +/-   0.0714095\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.0744981\tdiff(max) =   0.6115577\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000944 +/-   0.0659091\tparam2 =   -0.0000601 +/-   0.0255430\tdiff(rms) =   0.0638129\tdiff(max) =   0.3626493\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0010327 +/-   0.1217975\tparam2 =   -0.0011692 +/-   0.0239090\tdiff(rms) =   0.1203749\tdiff(max) =   0.8022967\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000304 +/-   0.0656764\tparam2 =    0.0000302 +/-   0.0255322\tdiff(rms) =   0.0635408\tdiff(max) =   0.4486744\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0000442 +/-   0.0275005\tparam2 =   -0.0002900 +/-   0.0259298\tdiff(rms) =   0.0087804\tdiff(max) =   0.0648868\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000465 +/-   0.0577384\tparam2 =    0.0000719 +/-   0.0255229\tdiff(rms) =   0.0555062\tdiff(max) =   0.3290350\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0000258 +/-   0.0267093\tparam2 =   -0.0015312 +/-   0.0264808\tdiff(rms) =   0.0169966\tdiff(max) =   0.0668323\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000135 +/-   0.0533266\tparam2 =   -0.0000505 +/-   0.0255297\tdiff(rms) =   0.0538071\tdiff(max) =   0.3301633\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention1.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0006804 +/-   0.0308564\tparam2 =    0.0005652 +/-   0.0251274\tdiff(rms) =   0.0392804\tdiff(max) =   0.2831591\n",
      "\u001b[32mdecoder.layers.2.add_norm1.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.9898975 +/-   0.0678242\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.0685724\tdiff(max) =   0.7326247\n",
      "\u001b[32mdecoder.layers.2.add_norm1.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0014985 +/-   0.2101439\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.2101493\tdiff(max) =   1.7137845\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000474 +/-   0.0818952\tparam2 =   -0.0000091 +/-   0.0255424\tdiff(rms) =   0.0778153\tdiff(max) =   0.4302495\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0000211 +/-   0.0916144\tparam2 =    0.0005573 +/-   0.0259088\tdiff(rms) =   0.0875047\tdiff(max) =   0.2765201\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000370 +/-   0.0804350\tparam2 =   -0.0000541 +/-   0.0255473\tdiff(rms) =   0.0763250\tdiff(max) =   0.4189903\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0004495 +/-   0.0284159\tparam2 =    0.0006293 +/-   0.0258630\tdiff(rms) =   0.0093052\tdiff(max) =   0.0400398\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000930 +/-   0.0828189\tparam2 =   -0.0000631 +/-   0.0255121\tdiff(rms) =   0.0782966\tdiff(max) =   0.3783790\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0000625 +/-   0.0168805\tparam2 =   -0.0014805 +/-   0.0257916\tdiff(rms) =   0.0268757\tdiff(max) =   0.0798241\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000504 +/-   0.0814826\tparam2 =    0.0000136 +/-   0.0255315\tdiff(rms) =   0.0786715\tdiff(max) =   0.5816227\n",
      "\u001b[32mdecoder.layers.2.multi_head_attention2.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0000296 +/-   0.0439937\tparam2 =   -0.0006724 +/-   0.0253661\tdiff(rms) =   0.0495375\tdiff(max) =   0.3539982\n",
      "\u001b[32mdecoder.layers.2.add_norm2.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.9472708 +/-   0.0959502\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.1094843\tdiff(max) =   0.9878912\n",
      "\u001b[32mdecoder.layers.2.add_norm2.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0223710 +/-   0.2249862\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.2260957\tdiff(max) =   1.7949632\n",
      "\u001b[32mdecoder.layers.2.feed_forward.linear1.weight\u001b[39m\n",
      "(2048, 512)         \tparam1 =   -0.0009783 +/-   0.0860684\tparam2 =    0.0000176 +/-   0.0255189\tdiff(rms) =   0.0834730\tdiff(max) =   0.8343935\n",
      "\u001b[32mdecoder.layers.2.feed_forward.linear1.bias\u001b[39m\n",
      "(2048,)             \tparam1 =   -0.0436391 +/-   0.0329485\tparam2 =   -0.0006480 +/-   0.0255923\tdiff(rms) =   0.0478547\tdiff(max) =   0.1950348\n",
      "\u001b[32mdecoder.layers.2.feed_forward.linear2.weight\u001b[39m\n",
      "(512, 2048)         \tparam1 =    0.0000395 +/-   0.0852658\tparam2 =    0.0000006 +/-   0.0127607\tdiff(rms) =   0.0850721\tdiff(max) =   6.1828012\n",
      "\u001b[32mdecoder.layers.2.feed_forward.linear2.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0021371 +/-   0.1627833\tparam2 =    0.0001018 +/-   0.0129891\tdiff(rms) =   0.1633864\tdiff(max) =   0.8590556\n",
      "\u001b[32mdecoder.layers.2.add_norm3.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.7151886 +/-   0.0660449\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.2923687\tdiff(max) =   0.9404781\n",
      "\u001b[32mdecoder.layers.2.add_norm3.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0142106 +/-   0.1069706\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.1079104\tdiff(max) =   1.3436595\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0002855 +/-   0.0702142\tparam2 =   -0.0000781 +/-   0.0255060\tdiff(rms) =   0.0676268\tdiff(max) =   0.3357294\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0076658 +/-   0.1018863\tparam2 =   -0.0009392 +/-   0.0254079\tdiff(rms) =   0.0969837\tdiff(max) =   0.3863564\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000414 +/-   0.0705962\tparam2 =    0.0000054 +/-   0.0255074\tdiff(rms) =   0.0682286\tdiff(max) =   0.6277449\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0024096 +/-   0.0390952\tparam2 =   -0.0016795 +/-   0.0254876\tdiff(rms) =   0.0299662\tdiff(max) =   0.1609826\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000182 +/-   0.0559090\tparam2 =   -0.0000285 +/-   0.0255051\tdiff(rms) =   0.0541348\tdiff(max) =   0.2626733\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0007278 +/-   0.0298965\tparam2 =    0.0009156 +/-   0.0252707\tdiff(rms) =   0.0238778\tdiff(max) =   0.1594030\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000028 +/-   0.0490566\tparam2 =   -0.0000470 +/-   0.0255211\tdiff(rms) =   0.0521690\tdiff(max) =   0.5167588\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention1.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0012198 +/-   0.0239544\tparam2 =    0.0010016 +/-   0.0250251\tdiff(rms) =   0.0331017\tdiff(max) =   0.3126550\n",
      "\u001b[32mdecoder.layers.3.add_norm1.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.9585185 +/-   0.0765375\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.0870558\tdiff(max) =   1.1716495\n",
      "\u001b[32mdecoder.layers.3.add_norm1.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0030476 +/-   0.1572865\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.1573160\tdiff(max) =   1.7952337\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000299 +/-   0.0882101\tparam2 =   -0.0000454 +/-   0.0255264\tdiff(rms) =   0.0844065\tdiff(max) =   0.4282493\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0008492 +/-   0.1384284\tparam2 =   -0.0019826 +/-   0.0258066\tdiff(rms) =   0.1335668\tdiff(max) =   0.4719830\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000900 +/-   0.0888987\tparam2 =    0.0000280 +/-   0.0255491\tdiff(rms) =   0.0845857\tdiff(max) =   0.4626634\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0005026 +/-   0.0287722\tparam2 =   -0.0006883 +/-   0.0256132\tdiff(rms) =   0.0133378\tdiff(max) =   0.0409802\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0001618 +/-   0.0982944\tparam2 =   -0.0000096 +/-   0.0255326\tdiff(rms) =   0.0932147\tdiff(max) =   0.4306797\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0005619 +/-   0.0158296\tparam2 =    0.0017063 +/-   0.0254333\tdiff(rms) =   0.0274663\tdiff(max) =   0.0667018\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000636 +/-   0.0936886\tparam2 =   -0.0000102 +/-   0.0255365\tdiff(rms) =   0.0915887\tdiff(max) =   0.7145064\n",
      "\u001b[32mdecoder.layers.3.multi_head_attention2.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0002479 +/-   0.0316867\tparam2 =   -0.0019103 +/-   0.0259418\tdiff(rms) =   0.0379548\tdiff(max) =   0.4398393\n",
      "\u001b[32mdecoder.layers.3.add_norm2.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.9441949 +/-   0.0899446\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.1058501\tdiff(max) =   1.3925159\n",
      "\u001b[32mdecoder.layers.3.add_norm2.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0053324 +/-   0.2118947\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.2119618\tdiff(max) =   2.2229476\n",
      "\u001b[32mdecoder.layers.3.feed_forward.linear1.weight\u001b[39m\n",
      "(2048, 512)         \tparam1 =   -0.0012388 +/-   0.0766670\tparam2 =    0.0000209 +/-   0.0255218\tdiff(rms) =   0.0743464\tdiff(max) =   0.7054989\n",
      "\u001b[32mdecoder.layers.3.feed_forward.linear1.bias\u001b[39m\n",
      "(2048,)             \tparam1 =   -0.0582492 +/-   0.0423908\tparam2 =   -0.0001639 +/-   0.0256146\tdiff(rms) =   0.0671634\tdiff(max) =   0.2942946\n",
      "\u001b[32mdecoder.layers.3.feed_forward.linear2.weight\u001b[39m\n",
      "(512, 2048)         \tparam1 =   -0.0000004 +/-   0.0801031\tparam2 =    0.0000069 +/-   0.0127540\tdiff(rms) =   0.0801466\tdiff(max) =   7.9789019\n",
      "\u001b[32mdecoder.layers.3.feed_forward.linear2.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0023934 +/-   0.1493899\tparam2 =    0.0005950 +/-   0.0129509\tdiff(rms) =   0.1492287\tdiff(max) =   1.2609823\n",
      "\u001b[32mdecoder.layers.3.add_norm3.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.8291425 +/-   0.0526092\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.1787736\tdiff(max) =   0.9095502\n",
      "\u001b[32mdecoder.layers.3.add_norm3.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0474955 +/-   0.0904932\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.1022000\tdiff(max) =   1.4052410\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000800 +/-   0.0629573\tparam2 =    0.0000727 +/-   0.0255220\tdiff(rms) =   0.0609888\tdiff(max) =   0.3459250\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0017293 +/-   0.0887405\tparam2 =   -0.0007817 +/-   0.0255086\tdiff(rms) =   0.0853420\tdiff(max) =   0.4763176\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000221 +/-   0.0602912\tparam2 =    0.0000673 +/-   0.0254935\tdiff(rms) =   0.0586310\tdiff(max) =   0.5956559\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0015836 +/-   0.0253339\tparam2 =   -0.0013508 +/-   0.0248998\tdiff(rms) =   0.0046022\tdiff(max) =   0.0329420\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0001810 +/-   0.0605843\tparam2 =   -0.0000671 +/-   0.0254870\tdiff(rms) =   0.0604434\tdiff(max) =   0.3030540\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0007591 +/-   0.0294036\tparam2 =    0.0006633 +/-   0.0256481\tdiff(rms) =   0.0173569\tdiff(max) =   0.0756223\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000156 +/-   0.0516357\tparam2 =   -0.0000053 +/-   0.0255165\tdiff(rms) =   0.0561357\tdiff(max) =   0.4513896\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention1.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0009315 +/-   0.0218350\tparam2 =    0.0023158 +/-   0.0254083\tdiff(rms) =   0.0332304\tdiff(max) =   0.3365423\n",
      "\u001b[32mdecoder.layers.4.add_norm1.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.9561525 +/-   0.0322017\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.0544018\tdiff(max) =   0.3236837\n",
      "\u001b[32mdecoder.layers.4.add_norm1.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0004945 +/-   0.2008632\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.2008638\tdiff(max) =   1.8686674\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000145 +/-   0.0922111\tparam2 =   -0.0000250 +/-   0.0255275\tdiff(rms) =   0.0883959\tdiff(max) =   0.4492854\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0016889 +/-   0.0903508\tparam2 =    0.0008615 +/-   0.0258429\tdiff(rms) =   0.0847395\tdiff(max) =   0.3438622\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000805 +/-   0.0905011\tparam2 =    0.0000948 +/-   0.0254757\tdiff(rms) =   0.0861684\tdiff(max) =   0.4650516\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0009539 +/-   0.0329131\tparam2 =    0.0007172 +/-   0.0250240\tdiff(rms) =   0.0201241\tdiff(max) =   0.0887638\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000009 +/-   0.0957131\tparam2 =   -0.0000735 +/-   0.0255086\tdiff(rms) =   0.0911356\tdiff(max) =   0.4853891\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0005848 +/-   0.0137445\tparam2 =    0.0019393 +/-   0.0260280\tdiff(rms) =   0.0273733\tdiff(max) =   0.0744475\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000469 +/-   0.0929544\tparam2 =    0.0000124 +/-   0.0255262\tdiff(rms) =   0.0919920\tdiff(max) =   0.9495560\n",
      "\u001b[32mdecoder.layers.4.multi_head_attention2.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0002985 +/-   0.0243482\tparam2 =    0.0005444 +/-   0.0264030\tdiff(rms) =   0.0334765\tdiff(max) =   0.3292758\n",
      "\u001b[32mdecoder.layers.4.add_norm2.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.9364974 +/-   0.0671418\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.0924154\tdiff(max) =   1.1141415\n",
      "\u001b[32mdecoder.layers.4.add_norm2.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0118407 +/-   0.2247996\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.2251112\tdiff(max) =   2.2003860\n",
      "\u001b[32mdecoder.layers.4.feed_forward.linear1.weight\u001b[39m\n",
      "(2048, 512)         \tparam1 =   -0.0016229 +/-   0.0642441\tparam2 =   -0.0000001 +/-   0.0254948\tdiff(rms) =   0.0609127\tdiff(max) =   0.4366151\n",
      "\u001b[32mdecoder.layers.4.feed_forward.linear1.bias\u001b[39m\n",
      "(2048,)             \tparam1 =   -0.0454229 +/-   0.0416064\tparam2 =   -0.0000433 +/-   0.0255045\tdiff(rms) =   0.0564068\tdiff(max) =   0.2668929\n",
      "\u001b[32mdecoder.layers.4.feed_forward.linear2.weight\u001b[39m\n",
      "(512, 2048)         \tparam1 =   -0.0000290 +/-   0.0720965\tparam2 =    0.0000165 +/-   0.0127541\tdiff(rms) =   0.0719574\tdiff(max) =   3.4618084\n",
      "\u001b[32mdecoder.layers.4.feed_forward.linear2.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0012751 +/-   0.1036974\tparam2 =    0.0000251 +/-   0.0131024\tdiff(rms) =   0.1051206\tdiff(max) =   1.3159802\n",
      "\u001b[32mdecoder.layers.4.add_norm3.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    1.0050170 +/-   0.0662543\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.0664440\tdiff(max) =   0.5562997\n",
      "\u001b[32mdecoder.layers.4.add_norm3.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0450367 +/-   0.1040524\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.1133808\tdiff(max) =   1.1466480\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000187 +/-   0.0650680\tparam2 =   -0.0000530 +/-   0.0255353\tdiff(rms) =   0.0599795\tdiff(max) =   0.3309952\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0009965 +/-   0.0655352\tparam2 =   -0.0009396 +/-   0.0265956\tdiff(rms) =   0.0569703\tdiff(max) =   0.1821512\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0001052 +/-   0.0624723\tparam2 =    0.0000173 +/-   0.0255194\tdiff(rms) =   0.0576174\tdiff(max) =   0.3203202\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0004037 +/-   0.0267851\tparam2 =   -0.0002035 +/-   0.0251354\tdiff(rms) =   0.0084766\tdiff(max) =   0.0578498\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000624 +/-   0.0315060\tparam2 =    0.0000739 +/-   0.0255479\tdiff(rms) =   0.0358549\tdiff(max) =   0.2132494\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0017167 +/-   0.0310314\tparam2 =   -0.0015678 +/-   0.0247894\tdiff(rms) =   0.0186952\tdiff(max) =   0.0656057\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000033 +/-   0.0192292\tparam2 =    0.0000052 +/-   0.0255393\tdiff(rms) =   0.0315998\tdiff(max) =   1.1027615\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention1.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0003894 +/-   0.0185254\tparam2 =   -0.0002276 +/-   0.0246554\tdiff(rms) =   0.0307977\tdiff(max) =   0.2768482\n",
      "\u001b[32mdecoder.layers.5.add_norm1.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.9087412 +/-   0.1207328\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.1513426\tdiff(max) =   1.1841626\n",
      "\u001b[32mdecoder.layers.5.add_norm1.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0053733 +/-   0.3115388\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.3115852\tdiff(max) =   2.1303997\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.q_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000322 +/-   0.1118522\tparam2 =   -0.0000135 +/-   0.0255156\tdiff(rms) =   0.1081783\tdiff(max) =   0.6681353\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.q_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0002293 +/-   0.0427754\tparam2 =    0.0005909 +/-   0.0254701\tdiff(rms) =   0.0355741\tdiff(max) =   0.1230451\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.k_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =   -0.0000410 +/-   0.0940721\tparam2 =    0.0000223 +/-   0.0255245\tdiff(rms) =   0.0899604\tdiff(max) =   0.4711074\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.k_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0006581 +/-   0.0338348\tparam2 =    0.0001484 +/-   0.0259335\tdiff(rms) =   0.0203243\tdiff(max) =   0.1056543\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.v_linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000527 +/-   0.0773700\tparam2 =    0.0000086 +/-   0.0255465\tdiff(rms) =   0.0746800\tdiff(max) =   0.3908639\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.v_linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0000126 +/-   0.0115635\tparam2 =   -0.0001590 +/-   0.0249743\tdiff(rms) =   0.0243086\tdiff(max) =   0.0679495\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.linear.weight\u001b[39m\n",
      "(512, 512)          \tparam1 =    0.0000139 +/-   0.0795880\tparam2 =   -0.0000092 +/-   0.0254970\tdiff(rms) =   0.0801217\tdiff(max) =   1.5427147\n",
      "\u001b[32mdecoder.layers.5.multi_head_attention2.linear.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0008469 +/-   0.0317333\tparam2 =    0.0004102 +/-   0.0250327\tdiff(rms) =   0.0410076\tdiff(max) =   0.4519526\n",
      "\u001b[32mdecoder.layers.5.add_norm2.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.8240629 +/-   0.1558917\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.2350661\tdiff(max) =   0.9291269\n",
      "\u001b[32mdecoder.layers.5.add_norm2.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0008339 +/-   0.2922931\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.2922943\tdiff(max) =   1.5410182\n",
      "\u001b[32mdecoder.layers.5.feed_forward.linear1.weight\u001b[39m\n",
      "(2048, 512)         \tparam1 =   -0.0004169 +/-   0.0366533\tparam2 =   -0.0000366 +/-   0.0255066\tdiff(rms) =   0.0265133\tdiff(max) =   0.3390183\n",
      "\u001b[32mdecoder.layers.5.feed_forward.linear1.bias\u001b[39m\n",
      "(2048,)             \tparam1 =   -0.0101399 +/-   0.0259832\tparam2 =   -0.0002296 +/-   0.0256033\tdiff(rms) =   0.0111846\tdiff(max) =   0.0568019\n",
      "\u001b[32mdecoder.layers.5.feed_forward.linear2.weight\u001b[39m\n",
      "(512, 2048)         \tparam1 =   -0.0000310 +/-   0.0372562\tparam2 =   -0.0000035 +/-   0.0127590\tdiff(rms) =   0.0355252\tdiff(max) =   1.7034404\n",
      "\u001b[32mdecoder.layers.5.feed_forward.linear2.bias\u001b[39m\n",
      "(512,)              \tparam1 =    0.0005097 +/-   0.0371605\tparam2 =    0.0007304 +/-   0.0127963\tdiff(rms) =   0.0381215\tdiff(max) =   0.4657410\n",
      "\u001b[32mdecoder.layers.5.add_norm3.norm.weight\u001b[39m\n",
      "(512,)              \tparam1 =    0.5811455 +/-   0.1018436\tparam2 =    1.0000000 +/-   0.0000000\tdiff(rms) =   0.4310583\tdiff(max) =   1.0135295\n",
      "\u001b[32mdecoder.layers.5.add_norm3.norm.bias\u001b[39m\n",
      "(512,)              \tparam1 =   -0.0166612 +/-   0.1207467\tparam2 =    0.0000000 +/-   0.0000000\tdiff(rms) =   0.1218908\tdiff(max) =   0.4363153\n"
     ]
    }
   ],
   "source": [
    "module1 = TransformerModel(vocab_size=tokenizer.get_vocab_size(), d_model=512)\n",
    "module1.load_state_dict(torch.load(\"base_100%_e03.pth\"))\n",
    "module2 = TransformerModel(vocab_size=tokenizer.get_vocab_size(), d_model=512)\n",
    "module2.load_state_dict(torch.load(\"base_100%_e00.pth\"))\n",
    "compare_params(module1, module2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.7%\n",
      "\u001b[31mIn\u001b[39m\n",
      "This \u001b[32mis\u001b[39m\n",
      "This is \u001b[31mthe\u001b[39m\n",
      "This is with \u001b[32mregard\u001b[39m\n",
      "This is with regard \u001b[32mto\u001b[39m\n",
      "This is with regard to \u001b[32mthe\u001b[39m\n",
      "This is with regard to the \u001b[32mquality\u001b[39m\n",
      "This is with regard to the quality \u001b[32mof\u001b[39m\n",
      "This is with regard to the quality of \u001b[32mthe\u001b[39m\n",
      "This is with regard to the quality of the \u001b[32mproducts\u001b[39m\n",
      "This is with regard to the quality of the products \u001b[31m,\u001b[39m\n",
      "This is with regard to the quality of the products that \u001b[32mare\u001b[39m\n",
      "This is with regard to the quality of the products that are \u001b[32moffered\u001b[39m\n",
      "This is with regard to the quality of the products that are offered \u001b[32mhere\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here \u001b[32m,\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , \u001b[32mas\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , as \u001b[32mwell\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , as well \u001b[32mas\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , as well as \u001b[32mthe\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , as well as the \u001b[31mTeam\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , as well as the team \u001b[31m,\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , as well as the team and \u001b[32mthe\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , as well as the team and the \u001b[31mbeautiful\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , as well as the team and the fantastic \u001b[31mOp\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , as well as the team and the fantastic setting \u001b[31min\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , as well as the team and the fantastic setting on \u001b[32mthe\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , as well as the team and the fantastic setting on the \u001b[32mOp\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , as well as the team and the fantastic setting on the Op \u001b[31mam\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , as well as the team and the fantastic setting on the Op schlag \u001b[31m.\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , as well as the team and the fantastic setting on the Op schlag in \u001b[31mam\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , as well as the team and the fantastic setting on the Op schlag in Kle \u001b[32mve\u001b[39m\n",
      "This is with regard to the quality of the products that are offered here , as well as the team and the fantastic setting on the Op schlag in Kle ve \u001b[32m.\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "rand_idx = np.random.randint(len(dataset.dataset[\"test\"][\"translation\"]))\n",
    "sample = dataset.dataset[\"test\"][\"translation\"][rand_idx]\n",
    "transformer.predict(sample[\"de\"], sample[\"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word  Fr isc us   the word  Fr n k   is in the form of the word  Fr n   was first used in the Latin - Dutch language , and the Latin word  Fr n   was only used in the form of the Latin word  Fr n k  ( 86 3 ) and the Latin word  Fr n  ( 86 3 ) in the form of the Latin word ) between the beginning of the beginning of the beginning of the year and the beginning of the year of the year , the year of the year , the year of the year , the year of the year , the \n",
      "The word  Fr isc us   the word  Fr n k   is in the form of the word  Fr n   was first used in the Latin - Dutch language , and the Latin word  Fr n   was only used in the form of the Latin word  Fr n k  ( 86 3 ) and the Latin word  Fr n  ( 86 3 ) in the form of the Latin word ) between the beginning of the beginning of the beginning of the year and the beginning of the year of the year , the year of the year , the year of the year , the year of the year , the\n"
     ]
    }
   ],
   "source": [
    "print(transformer.translate(\"\"\"Whrend die einzelnen Sprachen und Dialekte der germanischen Vlker eigene Namen trugen  Frnkisch, Gotisch usw. , gab es daneben fr den Gegensatz zwischen Latein und Volkssprache das Wort *eudisk, das aber vom Anfang (786) bis ins Jahr 1000 nur in der mittellateinischen Form theodiscus berliefert wurde. Der Ursprung dieses Wortes liegt, wie hnlichkeiten in der Lautform zeigen, mit groer Wahrscheinlichkeit im westfrnkischen (bzw. altniederlndischen) Gebiet des Frnkischen Reichs.[3] Die Franken nannten ihre Sprache anfangs frenkisk und die romanischen Sprachen wurden gemeinsam als *walhisk bezeichnet. Als aber im Verlauf des Frhmittelalters im zweisprachigen Westfrankenreich der politische und der sprachliche Begriff frnkisch sich nicht mehr deckten, weil auch die romanischsprachige Bevlkerung sich als frnkisch (vgl. neufranzsisch: franais) bezeichnete, setzte sich hier das Wort *eudisk fr den sprachlichen Gegensatz zu *walhisk durch und fand ein Bedeutungswandel statt, wobei die Bedeutung sich von Volkssprache in germanisch statt romanisch nderte. Da im ostfrnkischen Reich (dem spteren Deutschland) kein Anlass zu einem Bezeichnungswandel bestand, stellte sich dieser hier erst spter ein, vielleicht nach westfrnkischem Vorbild. Ganz allmhlich wandelte sich damit bei theodiscus/*eudisk die Bedeutung von volkssprachlich ber germanisch und, viele Jahrhunderte spter, letztendlich zu Deutsch.\"\"\", realtime=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1\n",
      "Source: Das sind etwa neun Milliarden Maiskrner.\n",
      "Target: That's about 9 billion individual kernels of corn.\n",
      "Prediction: These are approximately nine billion Ma isk r ner .\n",
      "\n",
      "#2\n",
      "Source: Feuerwehr zur Rettung eines Hndchens gerufen, das 15 Meter ber dem Boden auf einem gefhrlichen Felsvorsprung in einem Steinbruch festsa\n",
      "Target: Fire crews called to rescue lost puppy after she got stuck 50ft above the ground on precarious ledge in a quarry\n",
      "Prediction: The fire of a stone on the ground , which was founded in 15 meters above the rock , is a dangerous fire in front of a stone ' s throw ing in front of a stone .\n",
      "\n",
      "#3\n",
      "Source: Die Untersuchungsbeamten des Sheriffs von Lowndes County kamen zu dem Schluss, dass Johnson bei einem tragischen Unfall starb, was die Familie des 17-Jhrigen jedoch anzweifelt.\n",
      "Target: Lowndes County sheriff's investigators concluded Johnson died in a freak accident, but the 17-year-old's family disputes that.\n",
      "Prediction: The family of the tragic accident of the year - end of the year - 17 , Johnson County Johnson died , but that died in a tragic accident , which was the same .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    samples = dataset.dataset[\"test\"][\"translation\"]\n",
    "    idx = np.random.randint(len(samples))\n",
    "    sample = samples[idx]\n",
    "    print(f\"#{i+1}\")\n",
    "    print(f\"Source: {sample['de']}\")\n",
    "    print(f\"Target: {sample['en']}\")\n",
    "    print(f\"Prediction: {transformer.translate(sample['de'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 123676808, tot: 141799856, percentage: 87.22%\n",
      "count: 122343081, tot: 139480626, percentage: 87.71%\n"
     ]
    }
   ],
   "source": [
    "# dataset corpus length analysis\n",
    "for name in [\"src_len\", \"tgt_len\"]:\n",
    "    len_list = dataset.dataset[\"train\"][name]\n",
    "    tot = sum(len_list)\n",
    "    count = 0\n",
    "    for num in len_list:\n",
    "        if num <= 64:\n",
    "            count += num\n",
    "    print(f\"count: {count}, tot: {tot}, percentage: {count/tot*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63082496\n"
     ]
    }
   ],
   "source": [
    "# Total number of parameters\n",
    "total = 0\n",
    "for par in model.parameters():\n",
    "    total += par.numel()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.03% torch.Size([37000, 512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "1.66% torch.Size([2048, 512])\n",
      "0.00% torch.Size([2048])\n",
      "1.66% torch.Size([512, 2048])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "1.66% torch.Size([2048, 512])\n",
      "0.00% torch.Size([2048])\n",
      "1.66% torch.Size([512, 2048])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "1.66% torch.Size([2048, 512])\n",
      "0.00% torch.Size([2048])\n",
      "1.66% torch.Size([512, 2048])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "1.66% torch.Size([2048, 512])\n",
      "0.00% torch.Size([2048])\n",
      "1.66% torch.Size([512, 2048])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "1.66% torch.Size([2048, 512])\n",
      "0.00% torch.Size([2048])\n",
      "1.66% torch.Size([512, 2048])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "1.66% torch.Size([2048, 512])\n",
      "0.00% torch.Size([2048])\n",
      "1.66% torch.Size([512, 2048])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "1.66% torch.Size([2048, 512])\n",
      "0.00% torch.Size([2048])\n",
      "1.66% torch.Size([512, 2048])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "1.66% torch.Size([2048, 512])\n",
      "0.00% torch.Size([2048])\n",
      "1.66% torch.Size([512, 2048])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "1.66% torch.Size([2048, 512])\n",
      "0.00% torch.Size([2048])\n",
      "1.66% torch.Size([512, 2048])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "1.66% torch.Size([2048, 512])\n",
      "0.00% torch.Size([2048])\n",
      "1.66% torch.Size([512, 2048])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "1.66% torch.Size([2048, 512])\n",
      "0.00% torch.Size([2048])\n",
      "1.66% torch.Size([512, 2048])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.42% torch.Size([512, 512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "1.66% torch.Size([2048, 512])\n",
      "0.00% torch.Size([2048])\n",
      "1.66% torch.Size([512, 2048])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n",
      "0.00% torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# parameter distributions over the model\n",
    "for par in model.parameters():\n",
    "    print(f\"{100 * par.numel() / total:.2f}% {par.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 47/47 [01:50<00:00,  2.35s/it]\n",
      "That's 100 lines that end in a tokenized period ('.')\n",
      "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 12.15 50.6/18.2/7.6/3.4 (BP = 0.977 ratio = 0.977 hyp_len = 72510 ref_len = 74181)\n"
     ]
    }
   ],
   "source": [
    "result, ref, sys = transformer.evaluate_bleu(dataloader[\"validation\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The free mar kete ers at the Re ason Foundation are also fond of having drivers pay per mile .\n",
      "0 Also the idea of the free road to Re ason Foundation is to return to Re mark ter Foundation .\n",
      "1 There were large quantities of wood and bal es of stra w stored inside .\n",
      "1 It also made a lot of timber and all the timber .\n",
      "2 \" We need to have a better system ,\" he said .\n",
      "2  We need a better system .\n",
      "3 The film never sli ps into pr ur ience or sens ational ism - and that ' s the problem .\n",
      "3 The problem is its problem  never its film is in the way of the film and the sit t ings .\n",
      "4 As ked if he would return to the post of prime minister , Mr Blair was quoted by London ' s Even ing Standard as saying : \" Yes , sure , but it ' s not likely to happen is it , so ...\"\n",
      "4 The question is whether it is unlikely that the Prime Minister of London would return from the words of Prime Minister Blair , that is , but that is the standard of the  standard  that would return from London ...\n"
     ]
    }
   ],
   "source": [
    "# check the reference sentences and the predicted sentences\n",
    "for i in range(5):\n",
    "    print(i, ref[i])\n",
    "    print(i, sys[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
