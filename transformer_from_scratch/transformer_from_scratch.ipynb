{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Transformer from Attention is All You Need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  32\n",
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from dataset import Dataset\n",
    "from tokenizer import get_tokenizer\n",
    "from utils import NUM_PROC, DEVICE, free_memory\n",
    "from model import TransformerModel\n",
    "from transformer import Transformer\n",
    "\n",
    "\n",
    "print(\"Number of processors: \", NUM_PROC)\n",
    "print(\"Device: \", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Lite from Scratch\n",
    "\n",
    "Using half the dimension as the base model: $d_{\\rm model} = 256$, $d_{\\rm ff} = 1024$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "\n",
    "Byte-Pair Encoding with shared (English + German) vocabulary of 37000 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer from ../tokenizer-wmt14-de-en.json\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer(name=\"wmt14\", language=\"de-en\", vocab_size=37000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset is downloaded at ~/.cache/huggingface/datasets/. I've turned off dataset caching to avoid disk explosion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(name=\"wmt14\", language=\"de-en\", percentage=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6398adf8b2614c428b894db9c699134c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/450878 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6af4d582d584a4385760e6c87094142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d587df88b2344cc1a4d06be28507c961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/3003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.tokenize(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04e76730565425da2ccee0202c6e6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/450878 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29713bd9a9b44b78127e7bcfed3223c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/450878 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f67c03d6ea449c19cdd93db4d1da928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38432cdd56f4256833954641c98630f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade2173ea4db4ca3acdc30a89578282c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4c9f6c827f44ec93273d6e332eb796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/3003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataloader = {}\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    dataloader[split] = dataset.get_dataloader(split=split, batch_size=64, shuffle=True, min_len=1, max_len=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the transformer model\n",
    "model = TransformerModel(vocab_size=tokenizer.get_vocab_size(), d_model=256, dim_feedforward=1024).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=512**-0.5, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda nstep: min((nstep + 1) ** -0.5, (nstep + 1) * 4000 ** -1.5))\n",
    "loss_fn = nn.CrossEntropyLoss() # could add label smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# model.load_state_dict(torch.load(\"model_1.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    913 MiB |   7976 MiB | 210928 GiB | 210927 GiB |\n",
      "|       from large pool |    656 MiB |   7717 MiB | 205547 GiB | 205546 GiB |\n",
      "|       from small pool |    256 MiB |    418 MiB |   5381 GiB |   5381 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    913 MiB |   7976 MiB | 210928 GiB | 210927 GiB |\n",
      "|       from large pool |    656 MiB |   7717 MiB | 205547 GiB | 205546 GiB |\n",
      "|       from small pool |    256 MiB |    418 MiB |   5381 GiB |   5381 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |    913 MiB |   7976 MiB | 210870 GiB | 210869 GiB |\n",
      "|       from large pool |    656 MiB |   7717 MiB | 205489 GiB | 205488 GiB |\n",
      "|       from small pool |    256 MiB |    418 MiB |   5381 GiB |   5380 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   1488 MiB |  11270 MiB |  41858 MiB |  40370 MiB |\n",
      "|       from large pool |   1226 MiB |  10884 MiB |  40808 MiB |  39582 MiB |\n",
      "|       from small pool |    262 MiB |    430 MiB |   1050 MiB |    788 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 588544 KiB |   3205 MiB |  96247 GiB |  96246 GiB |\n",
      "|       from large pool | 583092 KiB |   3176 MiB |  90440 GiB |  90439 GiB |\n",
      "|       from small pool |   5452 KiB |     37 MiB |   5807 GiB |   5807 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    1158    |    1864    |   31226 K  |   31225 K  |\n",
      "|       from large pool |      21    |     289    |    9391 K  |    9391 K  |\n",
      "|       from small pool |    1137    |    1797    |   21835 K  |   21834 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    1158    |    1864    |   31226 K  |   31225 K  |\n",
      "|       from large pool |      21    |     289    |    9391 K  |    9391 K  |\n",
      "|       from small pool |    1137    |    1797    |   21835 K  |   21834 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     146    |     348    |    1099    |     953    |\n",
      "|       from large pool |      15    |     161    |     574    |     559    |\n",
      "|       from small pool |     131    |     215    |     525    |     394    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      46    |     136    |   15513 K  |   15513 K  |\n",
      "|       from large pool |      18    |     100    |    4986 K  |    4986 K  |\n",
      "|       from small pool |      28    |      56    |   10527 K  |   10527 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# free_memory(\"model\")\n",
    "free_memory()\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the transformer wrapper\n",
    "transformer = Transformer(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Epoch 1/1\n",
      "Accuracy: 0.0%, Avg loss: 10.600394  [    64/450878]  [0:00:00 < 1:07:33]\n",
      "Accuracy: 6.1%, Avg loss: 9.508562  [  6464/450878]  [0:00:11 < 0:13:04]\n",
      "Accuracy: 9.2%, Avg loss: 8.594700  [ 12864/450878]  [0:00:21 < 0:12:21]\n",
      "Accuracy: 10.1%, Avg loss: 7.280375  [ 19264/450878]  [0:00:32 < 0:12:00]\n",
      "Accuracy: 12.1%, Avg loss: 6.516609  [ 25664/450878]  [0:00:42 < 0:11:43]\n",
      "Accuracy: 15.1%, Avg loss: 6.074619  [ 32064/450878]  [0:00:52 < 0:11:31]\n",
      "Accuracy: 16.4%, Avg loss: 6.044272  [ 38464/450878]  [0:01:03 < 0:11:18]\n",
      "Accuracy: 16.7%, Avg loss: 5.908104  [ 44864/450878]  [0:01:13 < 0:11:05]\n",
      "Accuracy: 17.3%, Avg loss: 5.831823  [ 51264/450878]  [0:01:25 < 0:11:04]\n",
      "Accuracy: 19.1%, Avg loss: 5.533202  [ 57664/450878]  [0:01:35 < 0:10:50]\n",
      "Accuracy: 19.4%, Avg loss: 5.604733  [ 64064/450878]  [0:01:45 < 0:10:38]\n",
      "Accuracy: 20.9%, Avg loss: 5.427184  [ 70464/450878]  [0:01:55 < 0:10:25]\n",
      "Accuracy: 22.5%, Avg loss: 5.256050  [ 76864/450878]  [0:02:06 < 0:10:14]\n",
      "Accuracy: 21.2%, Avg loss: 5.180013  [ 83264/450878]  [0:02:16 < 0:10:03]\n",
      "Accuracy: 21.0%, Avg loss: 5.363179  [ 89664/450878]  [0:02:26 < 0:09:52]\n",
      "Accuracy: 22.1%, Avg loss: 5.331246  [ 96064/450878]  [0:02:37 < 0:09:40]\n",
      "Accuracy: 23.2%, Avg loss: 5.161789  [102464/450878]  [0:02:47 < 0:09:29]\n",
      "Accuracy: 23.8%, Avg loss: 4.974470  [108864/450878]  [0:03:01 < 0:09:29]\n",
      "Accuracy: 26.2%, Avg loss: 4.986141  [115264/450878]  [0:03:12 < 0:09:20]\n",
      "Accuracy: 25.8%, Avg loss: 4.939037  [121664/450878]  [0:03:22 < 0:09:09]\n",
      "Accuracy: 26.0%, Avg loss: 4.776317  [128064/450878]  [0:03:33 < 0:08:57]\n",
      "Accuracy: 28.4%, Avg loss: 4.716222  [134464/450878]  [0:03:43 < 0:08:46]\n",
      "Accuracy: 23.5%, Avg loss: 4.897870  [140864/450878]  [0:03:54 < 0:08:36]\n",
      "Accuracy: 27.0%, Avg loss: 4.752615  [147264/450878]  [0:04:04 < 0:08:24]\n",
      "Accuracy: 25.9%, Avg loss: 4.604896  [153664/450878]  [0:04:15 < 0:08:13]\n",
      "Accuracy: 27.4%, Avg loss: 4.602763  [160064/450878]  [0:04:25 < 0:08:02]\n",
      "Accuracy: 26.2%, Avg loss: 4.794686  [166464/450878]  [0:04:35 < 0:07:51]\n",
      "Accuracy: 26.4%, Avg loss: 4.667959  [172864/450878]  [0:04:46 < 0:07:40]\n",
      "Accuracy: 27.7%, Avg loss: 4.472009  [179264/450878]  [0:04:57 < 0:07:30]\n",
      "Accuracy: 27.3%, Avg loss: 4.589384  [185664/450878]  [0:05:07 < 0:07:19]\n",
      "Accuracy: 27.2%, Avg loss: 4.493224  [192064/450878]  [0:05:18 < 0:07:08]\n",
      "Accuracy: 27.4%, Avg loss: 4.542507  [198464/450878]  [0:05:28 < 0:06:57]\n",
      "Accuracy: 28.4%, Avg loss: 4.414369  [204864/450878]  [0:05:38 < 0:06:46]\n",
      "Accuracy: 27.2%, Avg loss: 4.643216  [211264/450878]  [0:05:48 < 0:06:35]\n",
      "Accuracy: 28.6%, Avg loss: 4.554634  [217664/450878]  [0:06:01 < 0:06:27]\n",
      "Accuracy: 30.0%, Avg loss: 4.333509  [224064/450878]  [0:06:12 < 0:06:17]\n",
      "Accuracy: 30.1%, Avg loss: 4.381060  [230464/450878]  [0:06:23 < 0:06:06]\n",
      "Accuracy: 30.2%, Avg loss: 4.425732  [236864/450878]  [0:06:33 < 0:05:55]\n",
      "Accuracy: 31.2%, Avg loss: 4.441890  [243264/450878]  [0:06:45 < 0:05:45]\n",
      "Accuracy: 27.6%, Avg loss: 4.395536  [249664/450878]  [0:06:55 < 0:05:34]\n",
      "Accuracy: 29.6%, Avg loss: 4.339670  [256064/450878]  [0:07:05 < 0:05:23]\n",
      "Accuracy: 29.5%, Avg loss: 4.296123  [262464/450878]  [0:07:16 < 0:05:13]\n",
      "Accuracy: 28.7%, Avg loss: 4.469353  [268864/450878]  [0:07:26 < 0:05:02]\n",
      "Accuracy: 31.0%, Avg loss: 4.306387  [275264/450878]  [0:07:36 < 0:04:51]\n",
      "Accuracy: 32.0%, Avg loss: 4.169805  [281664/450878]  [0:07:46 < 0:04:40]\n",
      "Accuracy: 31.0%, Avg loss: 4.099805  [288064/450878]  [0:07:57 < 0:04:29]\n",
      "Accuracy: 31.4%, Avg loss: 4.106005  [294464/450878]  [0:08:07 < 0:04:18]\n",
      "Accuracy: 33.6%, Avg loss: 4.022972  [300864/450878]  [0:08:19 < 0:04:09]\n",
      "Accuracy: 31.0%, Avg loss: 4.201358  [307264/450878]  [0:08:30 < 0:03:58]\n",
      "Accuracy: 32.9%, Avg loss: 4.188448  [313664/450878]  [0:08:40 < 0:03:47]\n",
      "Accuracy: 33.3%, Avg loss: 3.957568  [320064/450878]  [0:08:50 < 0:03:36]\n",
      "Accuracy: 34.9%, Avg loss: 3.930378  [326464/450878]  [0:09:00 < 0:03:26]\n",
      "Accuracy: 30.5%, Avg loss: 4.135233  [332864/450878]  [0:09:11 < 0:03:15]\n",
      "Accuracy: 34.0%, Avg loss: 3.991987  [339264/450878]  [0:09:21 < 0:03:04]\n",
      "Accuracy: 33.3%, Avg loss: 3.788705  [345664/450878]  [0:09:31 < 0:02:54]\n",
      "Accuracy: 30.2%, Avg loss: 4.133511  [352064/450878]  [0:09:43 < 0:02:43]\n",
      "Accuracy: 32.3%, Avg loss: 4.035072  [358464/450878]  [0:09:55 < 0:02:33]\n",
      "Accuracy: 34.1%, Avg loss: 4.018539  [364864/450878]  [0:10:06 < 0:02:23]\n",
      "Accuracy: 33.9%, Avg loss: 3.991220  [371264/450878]  [0:10:17 < 0:02:12]\n",
      "Accuracy: 30.5%, Avg loss: 4.149120  [377664/450878]  [0:10:27 < 0:02:01]\n",
      "Accuracy: 31.2%, Avg loss: 4.237926  [384064/450878]  [0:10:37 < 0:01:50]\n",
      "Accuracy: 33.8%, Avg loss: 3.786852  [390464/450878]  [0:10:48 < 0:01:40]\n",
      "Accuracy: 34.0%, Avg loss: 3.834055  [396864/450878]  [0:10:58 < 0:01:29]\n",
      "Accuracy: 34.3%, Avg loss: 3.831371  [403264/450878]  [0:11:08 < 0:01:18]\n",
      "Accuracy: 31.7%, Avg loss: 4.025260  [409664/450878]  [0:11:19 < 0:01:08]\n",
      "Accuracy: 33.8%, Avg loss: 3.871789  [416064/450878]  [0:11:29 < 0:00:57]\n",
      "Accuracy: 31.5%, Avg loss: 4.072171  [422464/450878]  [0:11:40 < 0:00:47]\n",
      "Accuracy: 33.9%, Avg loss: 3.874884  [428864/450878]  [0:11:50 < 0:00:36]\n",
      "Accuracy: 37.8%, Avg loss: 3.675547  [435264/450878]  [0:12:02 < 0:00:25]\n",
      "Accuracy: 32.6%, Avg loss: 3.939601  [441664/450878]  [0:12:13 < 0:00:15]\n",
      "Accuracy: 37.6%, Avg loss: 3.715786  [448064/450878]  [0:12:23 < 0:00:04]\n",
      "Validation Error: \n",
      " Accuracy: 23.1%, Avg loss: 5.704027 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "transformer.train(dataloader, model, loss_fn, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 26.1%\n",
      "\u001b[32mThe\u001b[39m\n",
      "The \u001b[31msame\u001b[39m\n",
      "The Kl \u001b[31ms\u001b[39m\n",
      "The Kl user \u001b[31mand\u001b[39m\n",
      "The Kl user lights \u001b[31mand\u001b[39m\n",
      "The Kl user lights protect \u001b[31mthe\u001b[39m\n",
      "The Kl user lights protect cycl \u001b[31mand\u001b[39m\n",
      "The Kl user lights protect cycl ists \u001b[31mand\u001b[39m\n",
      "The Kl user lights protect cycl ists , \u001b[31mand\u001b[39m\n",
      "The Kl user lights protect cycl ists , as \u001b[32mwell\u001b[39m\n",
      "The Kl user lights protect cycl ists , as well \u001b[32mas\u001b[39m\n",
      "The Kl user lights protect cycl ists , as well as \u001b[31mthe\u001b[39m\n",
      "The Kl user lights protect cycl ists , as well as those \u001b[31mwho\u001b[39m\n",
      "The Kl user lights protect cycl ists , as well as those travelling \u001b[31mand\u001b[39m\n",
      "The Kl user lights protect cycl ists , as well as those travelling by \u001b[31mthe\u001b[39m\n",
      "The Kl user lights protect cycl ists , as well as those travelling by bus \u001b[31mh\u001b[39m\n",
      "The Kl user lights protect cycl ists , as well as those travelling by bus and \u001b[32mthe\u001b[39m\n",
      "The Kl user lights protect cycl ists , as well as those travelling by bus and the \u001b[31mother\u001b[39m\n",
      "The Kl user lights protect cycl ists , as well as those travelling by bus and the residents \u001b[31m.\u001b[39m\n",
      "The Kl user lights protect cycl ists , as well as those travelling by bus and the residents of \u001b[31mthe\u001b[39m\n",
      "The Kl user lights protect cycl ists , as well as those travelling by bus and the residents of Berg \u001b[31m.\u001b[39m\n",
      "The Kl user lights protect cycl ists , as well as those travelling by bus and the residents of Berg le \u001b[32m.\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "sample = dataset.dataset[\"test\"][\"translation\"][5]\n",
    "transformer.predict(sample[\"de\"], sample[\"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a pleasure to make a clear distinction .\n"
     ]
    }
   ],
   "source": [
    "print(transformer.translate(\"Ich bin ein Berliner.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1\n",
      "Source: Gutach: Noch mehr Sicherheit für Fußgänger\n",
      "Target: Gutach: Increased safety for pedestrians\n",
      "Prediction: The Council is also a more important point .\n",
      "\n",
      "#2\n",
      "Source: Sie stehen keine 100 Meter voneinander entfernt: Am Dienstag ist in Gutach die neue B 33-Fußgängerampel am Dorfparkplatz in Betrieb genommen worden - in Sichtweite der älteren Rathausampel.\n",
      "Target: They are not even 100 metres apart: On Tuesday, the new B 33 pedestrian lights in Dorfparkplatz in Gutach became operational - within view of the existing Town Hall traffic lights.\n",
      "Prediction: You are not going to have the same resources , which you know : ' You are not being used in the new form of the new waste - in the new Sea .\n",
      "\n",
      "#3\n",
      "Source: Zwei Anlagen so nah beieinander: Absicht oder Schildbürgerstreich?\n",
      "Target: Two sets of lights so close to one another: intentional or just a silly error?\n",
      "Prediction: Thirdly , what are the same kind of or whether or not they are they going to be a good example ?\n",
      "\n",
      "#4\n",
      "Source: Diese Frage hat Gutachs Bürgermeister gestern klar beantwortet.\n",
      "Target: Yesterday, Gutacht's Mayor gave a clear answer to this question.\n",
      "Prediction: This issue has been raised by this question .\n",
      "\n",
      "#5\n",
      "Source: \"Die Rathausampel ist damals installiert worden, weil diese den Schulweg sichert\", erläuterte Eckert gestern.\n",
      "Target: \"At the time, the Town Hall traffic lights were installed because this was a school route,\" explained Eckert yesterday.\n",
      "Prediction: The only thing is that this disease was not the case of the Prestige .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    samples = dataset.dataset[\"test\"][\"translation\"]\n",
    "    idx = np.random.randint(len(samples))\n",
    "    sample = samples[i]\n",
    "    print(f\"#{i+1}\")\n",
    "    print(f\"Source: {sample['de']}\")\n",
    "    print(f\"Target: {sample['en']}\")\n",
    "    print(f\"Prediction: {transformer.translate(sample['de'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 14302156, tot: 14303264, percentage: 99.99%\n",
      "count: 14339828, tot: 14340777, percentage: 99.99%\n"
     ]
    }
   ],
   "source": [
    "for name in [\"src_len\", \"tgt_len\"]:\n",
    "    len_list = dataset.dataset[\"train\"][name]\n",
    "    tot = sum(len_list)\n",
    "    count = 0\n",
    "    for num in len_list:\n",
    "        if num <= 256:\n",
    "            count += num\n",
    "    print(f\"count: {count}, tot: {tot}, percentage: {count/tot*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128]) torch.Size([64, 128]) torch.Size([64, 128]) torch.Size([64, 128])\n",
      "torch.Size([64, 128, 256])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader[\"train\"]:\n",
    "    x, x_mask, y, y_mask = batch.values()\n",
    "    print(x.shape, x_mask.shape, y.shape, y_mask.shape)\n",
    "    x = model.embedding(x.to(DEVICE))\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
